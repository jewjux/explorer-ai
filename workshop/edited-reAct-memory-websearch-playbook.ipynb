{"cells":[{"cell_type":"markdown","metadata":{"id":"9coJgIqI7SGb"},"source":["# Introduction"]},{"cell_type":"markdown","metadata":{"id":"wRJo9kyn1DTD"},"source":["## Build a Conversational Web Search ReAct Agent with NVIDIA NIMS\n","\n","This playbook demonstrates how to enable tool calling with memory on Llama 3.1 70B Instruct model using LangGraph, Tavily. Model inference is completed by API via NVIDIA NIMs. We will first explore implementing each feature/component individually. We explore implementing only persistent memory on LangGraph, then creating a ReAct agent with only Tavily web search tool -- and then lastly how both concepts can be combined for a ReAct agent with conversational memory and web search capabilities.\n","\n","**Notebook Goals:**\n","\n","Build a ReAct Agent with\n","1. Conversational Memory (remembers context, names, roles)\n","2. Web Search Tool (real-time search using Tavily)\n","3. NVIDIA Llama 3.1 70B Instruct for inference\n","4. LangGraph to orchestrate reasoning, memory, and tool use\n"]},{"cell_type":"markdown","metadata":{"id":"UZiF1SUR6clH"},"source":["## Key Components and Why They're Used\n","\n","| Component              | Purpose                                                        |\n","|------------------------|----------------------------------------------------------------|\n","| LangGraph              | Orchestrates state transitions, memory, and tool use           |\n","| MemorySaver            | Saves state so the agent remembers conversation                |\n","| TavilySearchResults    | Real-time web search API for factual augmentation              |\n","| create_react_agent()   | Prebuilt function to create a LangGraph-powered ReAct agent with memory + tools |\n","| ChatNVIDIA             | Calls NVIDIA's Llama 3.1 70B via API to generate responses     |\n"]},{"cell_type":"markdown","metadata":{"id":"YuHo8qLF7hyz"},"source":["# Setup"]},{"cell_type":"markdown","metadata":{"id":"UbtCum1i1DTE"},"source":["## Instructions to Configure Jupyter Notebook Environment\n","\n","**Step 1: Set Up Your Accounts and API Keys (free)**\n","\n","- Generate a NVIDIA NIMs API Key: [Log in to your account, navigate to your account settings, and generate an API key](https://build.nvidia.com/meta/llama-3_1-70b-instruct).\n","- Generate a LangSmith API Key: [Log into your account and generate an API key](https://smith.langchain.com/settings)\n","- Generate a Tavily Web Search Key: [Log into your account and generate an API key](https://app.tavily.com/)\n","\n","**Step 2: Download the packages**\n","\n","- Create a jupyter notebook kernel with the required packages (in requirements.txt)"]},{"cell_type":"markdown","metadata":{"id":"f6QGzG-S1osX"},"source":["For running the notebook locally:"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# !pip install --upgrade pip"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"vs-cPllL1DTE"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting aiohappyeyeballs==2.6.1 (from -r requirements.txt (line 1))\n","  Obtaining dependency information for aiohappyeyeballs==2.6.1 from https://files.pythonhosted.org/packages/0f/15/5bf3b99495fb160b63f95972b81750f18f7f4e02ad051373b669d17d44f2/aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata\n","  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n","Collecting aiohttp==3.11.16 (from -r requirements.txt (line 2))\n","  Obtaining dependency information for aiohttp==3.11.16 from https://files.pythonhosted.org/packages/34/23/eedf80ec42865ea5355b46265a2433134138eff9a4fea17e1348530fa4ae/aiohttp-3.11.16-cp311-cp311-macosx_11_0_arm64.whl.metadata\n","  Using cached aiohttp-3.11.16-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.7 kB)\n","Collecting aiosignal==1.3.2 (from -r requirements.txt (line 3))\n","  Obtaining dependency information for aiosignal==1.3.2 from https://files.pythonhosted.org/packages/ec/6a/bc7e17a3e87a2985d3e8f4da4cd0f481060eb78fb08596c42be62c90a4d9/aiosignal-1.3.2-py2.py3-none-any.whl.metadata\n","  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n","Collecting annotated-types==0.7.0 (from -r requirements.txt (line 4))\n","  Obtaining dependency information for annotated-types==0.7.0 from https://files.pythonhosted.org/packages/78/b6/6307fbef88d9b5ee7421e68d78a9f162e0da4900bc5f5793f6d3d0e34fb8/annotated_types-0.7.0-py3-none-any.whl.metadata\n","  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n","Collecting anyio==4.9.0 (from -r requirements.txt (line 5))\n","  Obtaining dependency information for anyio==4.9.0 from https://files.pythonhosted.org/packages/a1/ee/48ca1a7c89ffec8b6a0c5d02b89c305671d5ffd8d3c94acf8b8c408575bb/anyio-4.9.0-py3-none-any.whl.metadata\n","  Using cached anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n","Requirement already satisfied: asttokens==3.0.0 in /Users/jewel/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (3.0.0)\n","Collecting attrs==25.3.0 (from -r requirements.txt (line 7))\n","  Obtaining dependency information for attrs==25.3.0 from https://files.pythonhosted.org/packages/77/06/bb80f5f86020c4551da315d78b3ab75e8228f89f0162f2c3a819e407941a/attrs-25.3.0-py3-none-any.whl.metadata\n","  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n","Collecting certifi==2025.1.31 (from -r requirements.txt (line 8))\n","  Obtaining dependency information for certifi==2025.1.31 from https://files.pythonhosted.org/packages/38/fc/bce832fd4fd99766c04d1ee0eead6b0ec6486fb100ae5e74c1d91292b982/certifi-2025.1.31-py3-none-any.whl.metadata\n","  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n","Collecting charset-normalizer==3.4.1 (from -r requirements.txt (line 9))\n","  Obtaining dependency information for charset-normalizer==3.4.1 from https://files.pythonhosted.org/packages/72/80/41ef5d5a7935d2d3a773e3eaebf0a9350542f2cab4eac59a7a4741fbbbbe/charset_normalizer-3.4.1-cp311-cp311-macosx_10_9_universal2.whl.metadata\n","  Using cached charset_normalizer-3.4.1-cp311-cp311-macosx_10_9_universal2.whl.metadata (35 kB)\n","Requirement already satisfied: comm==0.2.2 in /Users/jewel/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from -r requirements.txt (line 10)) (0.2.2)\n","Collecting dataclasses-json==0.6.7 (from -r requirements.txt (line 11))\n","  Obtaining dependency information for dataclasses-json==0.6.7 from https://files.pythonhosted.org/packages/c3/be/d0d44e092656fe7a06b55e6103cbce807cdbdee17884a5367c68c9860853/dataclasses_json-0.6.7-py3-none-any.whl.metadata\n","  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n","Collecting debugpy==1.8.13 (from -r requirements.txt (line 12))\n","  Obtaining dependency information for debugpy==1.8.13 from https://files.pythonhosted.org/packages/31/90/dd2fcad8364f0964f476537481985198ce6e879760281ad1cec289f1aa71/debugpy-1.8.13-cp311-cp311-macosx_14_0_universal2.whl.metadata\n","  Using cached debugpy-1.8.13-cp311-cp311-macosx_14_0_universal2.whl.metadata (1.3 kB)\n","Requirement already satisfied: decorator==5.2.1 in /Users/jewel/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from -r requirements.txt (line 13)) (5.2.1)\n","Collecting distro==1.9.0 (from -r requirements.txt (line 14))\n","  Obtaining dependency information for distro==1.9.0 from https://files.pythonhosted.org/packages/12/b3/231ffd4ab1fc9d679809f356cebee130ac7daa00d6d6f3206dd4fd137e9e/distro-1.9.0-py3-none-any.whl.metadata\n","  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n","Requirement already satisfied: executing==2.2.0 in /Users/jewel/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from -r requirements.txt (line 15)) (2.2.0)\n","Collecting frozenlist==1.5.0 (from -r requirements.txt (line 16))\n","  Obtaining dependency information for frozenlist==1.5.0 from https://files.pythonhosted.org/packages/2c/31/ab01375682f14f7613a1ade30149f684c84f9b8823a4391ed950c8285656/frozenlist-1.5.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n","  Using cached frozenlist-1.5.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (13 kB)\n","Collecting greenlet==3.1.1 (from -r requirements.txt (line 17))\n","  Obtaining dependency information for greenlet==3.1.1 from https://files.pythonhosted.org/packages/28/62/1c2665558618553c42922ed47a4e6d6527e2fa3516a8256c2f431c5d0441/greenlet-3.1.1-cp311-cp311-macosx_11_0_universal2.whl.metadata\n","  Using cached greenlet-3.1.1-cp311-cp311-macosx_11_0_universal2.whl.metadata (3.8 kB)\n","Collecting h11==0.14.0 (from -r requirements.txt (line 18))\n","  Obtaining dependency information for h11==0.14.0 from https://files.pythonhosted.org/packages/95/04/ff642e65ad6b90db43e668d70ffb6736436c7ce41fcc549f4e9472234127/h11-0.14.0-py3-none-any.whl.metadata\n","  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n","Collecting httpcore==1.0.7 (from -r requirements.txt (line 19))\n","  Obtaining dependency information for httpcore==1.0.7 from https://files.pythonhosted.org/packages/87/f5/72347bc88306acb359581ac4d52f23c0ef445b57157adedb9aee0cd689d2/httpcore-1.0.7-py3-none-any.whl.metadata\n","  Using cached httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n","Collecting httpx==0.28.1 (from -r requirements.txt (line 20))\n","  Obtaining dependency information for httpx==0.28.1 from https://files.pythonhosted.org/packages/2a/39/e50c7c3a983047577ee07d2a9e53faf5a69493943ec3f6a384bdc792deb2/httpx-0.28.1-py3-none-any.whl.metadata\n","  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n","Collecting httpx-sse==0.4.0 (from -r requirements.txt (line 21))\n","  Obtaining dependency information for httpx-sse==0.4.0 from https://files.pythonhosted.org/packages/e1/9b/a181f281f65d776426002f330c31849b86b31fc9d848db62e16f03ff739f/httpx_sse-0.4.0-py3-none-any.whl.metadata\n","  Using cached httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n","Collecting idna==3.10 (from -r requirements.txt (line 22))\n","  Obtaining dependency information for idna==3.10 from https://files.pythonhosted.org/packages/76/c6/c88e154df9c4e1a2a66ccf0005a88dfb2650c1dffb6f5ce603dfbd452ce3/idna-3.10-py3-none-any.whl.metadata\n","  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: ipykernel==6.29.5 in /Users/jewel/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from -r requirements.txt (line 23)) (6.29.5)\n","Collecting ipython==9.0.2 (from -r requirements.txt (line 24))\n","  Obtaining dependency information for ipython==9.0.2 from https://files.pythonhosted.org/packages/20/3a/917cb9e72f4e1a4ea13c862533205ae1319bd664119189ee5cc9e4e95ebf/ipython-9.0.2-py3-none-any.whl.metadata\n","  Using cached ipython-9.0.2-py3-none-any.whl.metadata (4.3 kB)\n","Requirement already satisfied: ipython_pygments_lexers==1.1.1 in /Users/jewel/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from -r requirements.txt (line 25)) (1.1.1)\n","Requirement already satisfied: jedi==0.19.2 in /Users/jewel/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from -r requirements.txt (line 26)) (0.19.2)\n","Collecting jiter==0.9.0 (from -r requirements.txt (line 27))\n","  Obtaining dependency information for jiter==0.9.0 from https://files.pythonhosted.org/packages/fb/1b/a7e5e42db9fa262baaa9489d8d14ca93f8663e7f164ed5e9acc9f467fc00/jiter-0.9.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n","  Using cached jiter-0.9.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.2 kB)\n","Collecting jsonpatch==1.33 (from -r requirements.txt (line 28))\n","  Obtaining dependency information for jsonpatch==1.33 from https://files.pythonhosted.org/packages/73/07/02e16ed01e04a374e644b575638ec7987ae846d25ad97bcc9945a3ee4b0e/jsonpatch-1.33-py2.py3-none-any.whl.metadata\n","  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n","Collecting jsonpointer==3.0.0 (from -r requirements.txt (line 29))\n","  Obtaining dependency information for jsonpointer==3.0.0 from https://files.pythonhosted.org/packages/71/92/5e77f98553e9e75130c78900d000368476aed74276eb8ae8796f65f00918/jsonpointer-3.0.0-py2.py3-none-any.whl.metadata\n","  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n","Requirement already satisfied: jupyter_client==8.6.3 in /Users/jewel/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from -r requirements.txt (line 30)) (8.6.3)\n","Requirement already satisfied: jupyter_core==5.7.2 in /Users/jewel/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from -r requirements.txt (line 31)) (5.7.2)\n","Collecting langchain==0.3.18 (from -r requirements.txt (line 32))\n","  Obtaining dependency information for langchain==0.3.18 from https://files.pythonhosted.org/packages/93/83/a4b41a1cf8b22fd708104d50edf98b720aa28647d3083d83b8348927a786/langchain-0.3.18-py3-none-any.whl.metadata\n","  Using cached langchain-0.3.18-py3-none-any.whl.metadata (7.8 kB)\n","Collecting langchain-community==0.3.17 (from -r requirements.txt (line 33))\n","  Obtaining dependency information for langchain-community==0.3.17 from https://files.pythonhosted.org/packages/7e/31/39c30cab465774835e2c18d3746587e6fd0c9f7265b1c6b1fcd2e1684dd2/langchain_community-0.3.17-py3-none-any.whl.metadata\n","  Using cached langchain_community-0.3.17-py3-none-any.whl.metadata (2.4 kB)\n","Collecting langchain-core==0.3.49 (from -r requirements.txt (line 34))\n","  Obtaining dependency information for langchain-core==0.3.49 from https://files.pythonhosted.org/packages/dd/35/27164f5f23517be8639b518130e6235293dae52c41988790e0b50dd7ba11/langchain_core-0.3.49-py3-none-any.whl.metadata\n","  Using cached langchain_core-0.3.49-py3-none-any.whl.metadata (5.9 kB)\n","Collecting langchain-nvidia-ai-endpoints==0.3.9 (from -r requirements.txt (line 35))\n","  Obtaining dependency information for langchain-nvidia-ai-endpoints==0.3.9 from https://files.pythonhosted.org/packages/5f/a0/1796982537830d0cd65d7e56982372ae3a55e3495dbab6792e61b07d6a56/langchain_nvidia_ai_endpoints-0.3.9-py3-none-any.whl.metadata\n","  Using cached langchain_nvidia_ai_endpoints-0.3.9-py3-none-any.whl.metadata (11 kB)\n","Collecting langchain-text-splitters==0.3.6 (from -r requirements.txt (line 36))\n","  Obtaining dependency information for langchain-text-splitters==0.3.6 from https://files.pythonhosted.org/packages/4c/f8/6b82af988e65af9697f6a2f25373fb173fd32d48b62772a8773c5184c870/langchain_text_splitters-0.3.6-py3-none-any.whl.metadata\n","  Using cached langchain_text_splitters-0.3.6-py3-none-any.whl.metadata (1.9 kB)\n","Collecting langgraph==0.3.22 (from -r requirements.txt (line 37))\n","  Obtaining dependency information for langgraph==0.3.22 from https://files.pythonhosted.org/packages/ec/3c/06e31381a04048269cb91785dff6b41c7c2034af681b86d26ea154fa4b00/langgraph-0.3.22-py3-none-any.whl.metadata\n","  Using cached langgraph-0.3.22-py3-none-any.whl.metadata (7.7 kB)\n","Collecting langgraph-checkpoint==2.0.23 (from -r requirements.txt (line 38))\n","  Obtaining dependency information for langgraph-checkpoint==2.0.23 from https://files.pythonhosted.org/packages/ec/8d/e23bc15809c4a29e83efab34e7ff1ffb6dadac26b87aca98242ac6033934/langgraph_checkpoint-2.0.23-py3-none-any.whl.metadata\n","  Using cached langgraph_checkpoint-2.0.23-py3-none-any.whl.metadata (4.6 kB)\n","Collecting langgraph-prebuilt==0.1.7 (from -r requirements.txt (line 39))\n","  Obtaining dependency information for langgraph-prebuilt==0.1.7 from https://files.pythonhosted.org/packages/52/c2/e88798e0c698ae92f30b41966a781e1b28fa48ae4825462062722d1942bb/langgraph_prebuilt-0.1.7-py3-none-any.whl.metadata\n","  Using cached langgraph_prebuilt-0.1.7-py3-none-any.whl.metadata (5.0 kB)\n","Collecting langgraph-sdk==0.1.60 (from -r requirements.txt (line 40))\n","  Obtaining dependency information for langgraph-sdk==0.1.60 from https://files.pythonhosted.org/packages/79/95/70f58cdf34a0f46131424ff16f1e3f52e196cbfc0802048475a7640f093e/langgraph_sdk-0.1.60-py3-none-any.whl.metadata\n","  Using cached langgraph_sdk-0.1.60-py3-none-any.whl.metadata (1.8 kB)\n","Collecting langsmith==0.3.22 (from -r requirements.txt (line 41))\n","  Obtaining dependency information for langsmith==0.3.22 from https://files.pythonhosted.org/packages/0b/00/bfbc109003d26f183141252d7ab9230955908eeff8bdfdc9e4f2887c9ccb/langsmith-0.3.22-py3-none-any.whl.metadata\n","  Using cached langsmith-0.3.22-py3-none-any.whl.metadata (15 kB)\n","Collecting marshmallow==3.26.1 (from -r requirements.txt (line 42))\n","  Obtaining dependency information for marshmallow==3.26.1 from https://files.pythonhosted.org/packages/34/75/51952c7b2d3873b44a0028b1bd26a25078c18f92f256608e8d1dc61b39fd/marshmallow-3.26.1-py3-none-any.whl.metadata\n","  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n","Requirement already satisfied: matplotlib-inline==0.1.7 in /Users/jewel/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from -r requirements.txt (line 43)) (0.1.7)\n","Collecting multidict==6.3.1 (from -r requirements.txt (line 44))\n","  Obtaining dependency information for multidict==6.3.1 from https://files.pythonhosted.org/packages/cf/f7/6b0a993d3d48ca9a4d5ce008b1789a527dbbddaaf37a6612cd620bd22a85/multidict-6.3.1-cp311-cp311-macosx_11_0_arm64.whl.metadata\n","  Using cached multidict-6.3.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.1 kB)\n","Collecting mypy-extensions==1.0.0 (from -r requirements.txt (line 45))\n","  Obtaining dependency information for mypy-extensions==1.0.0 from https://files.pythonhosted.org/packages/2a/e2/5d3f6ada4297caebe1a2add3b126fe800c96f56dbe5d1988a2cbe0b267aa/mypy_extensions-1.0.0-py3-none-any.whl.metadata\n","  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n","Requirement already satisfied: nest-asyncio==1.6.0 in /Users/jewel/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from -r requirements.txt (line 46)) (1.6.0)\n","Collecting numpy==1.26.4 (from -r requirements.txt (line 47))\n","  Obtaining dependency information for numpy==1.26.4 from https://files.pythonhosted.org/packages/1a/2e/151484f49fd03944c4a3ad9c418ed193cfd02724e138ac8a9505d056c582/numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl.metadata\n","  Using cached numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (114 kB)\n","Collecting openai==1.70.0 (from -r requirements.txt (line 48))\n","  Obtaining dependency information for openai==1.70.0 from https://files.pythonhosted.org/packages/e2/39/c4b38317d2c702c4bc763957735aaeaf30dfc43b5b824121c49a4ba7ba0f/openai-1.70.0-py3-none-any.whl.metadata\n","  Using cached openai-1.70.0-py3-none-any.whl.metadata (25 kB)\n","Collecting orjson==3.10.16 (from -r requirements.txt (line 49))\n","  Obtaining dependency information for orjson==3.10.16 from https://files.pythonhosted.org/packages/97/29/43f91a5512b5d2535594438eb41c5357865fd5e64dec745d90a588820c75/orjson-3.10.16-cp311-cp311-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata\n","  Using cached orjson-3.10.16-cp311-cp311-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (41 kB)\n","Collecting ormsgpack==1.9.1 (from -r requirements.txt (line 50))\n","  Obtaining dependency information for ormsgpack==1.9.1 from https://files.pythonhosted.org/packages/d8/3b/388e7915a28db6ab3daedfd4937bd7b063c50dd1543068daa31c0a3b70ed/ormsgpack-1.9.1-cp311-cp311-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl.metadata\n","  Using cached ormsgpack-1.9.1-cp311-cp311-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl.metadata (43 kB)\n","Collecting packaging==24.2 (from -r requirements.txt (line 51))\n","  Obtaining dependency information for packaging==24.2 from https://files.pythonhosted.org/packages/88/ef/eb23f262cca3c0c4eb7ab1933c3b1f03d021f2c48f54763065b6f0e321be/packaging-24.2-py3-none-any.whl.metadata\n","  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n","Requirement already satisfied: parso==0.8.4 in /Users/jewel/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from -r requirements.txt (line 52)) (0.8.4)\n","Requirement already satisfied: pexpect==4.9.0 in /Users/jewel/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from -r requirements.txt (line 53)) (4.9.0)\n","Requirement already satisfied: platformdirs==4.3.7 in /Users/jewel/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from -r requirements.txt (line 54)) (4.3.7)\n","Collecting prompt_toolkit==3.0.50 (from -r requirements.txt (line 55))\n","  Obtaining dependency information for prompt_toolkit==3.0.50 from https://files.pythonhosted.org/packages/e4/ea/d836f008d33151c7a1f62caf3d8dd782e4d15f6a43897f64480c2b8de2ad/prompt_toolkit-3.0.50-py3-none-any.whl.metadata\n","  Using cached prompt_toolkit-3.0.50-py3-none-any.whl.metadata (6.6 kB)\n","Collecting propcache==0.3.1 (from -r requirements.txt (line 56))\n","  Obtaining dependency information for propcache==0.3.1 from https://files.pythonhosted.org/packages/e2/c8/b649ed972433c3f0d827d7f0cf9ea47162f4ef8f4fe98c5f3641a0bc63ff/propcache-0.3.1-cp311-cp311-macosx_11_0_arm64.whl.metadata\n","  Using cached propcache-0.3.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (10 kB)\n","Requirement already satisfied: psutil==7.0.0 in /Users/jewel/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from -r requirements.txt (line 57)) (7.0.0)\n","Requirement already satisfied: ptyprocess==0.7.0 in /Users/jewel/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from -r requirements.txt (line 58)) (0.7.0)\n","Requirement already satisfied: pure_eval==0.2.3 in /Users/jewel/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from -r requirements.txt (line 59)) (0.2.3)\n","Collecting pydantic==2.11.1 (from -r requirements.txt (line 60))\n","  Obtaining dependency information for pydantic==2.11.1 from https://files.pythonhosted.org/packages/cc/12/f9221a949f2419e2e23847303c002476c26fbcfd62dc7f3d25d0bec5ca99/pydantic-2.11.1-py3-none-any.whl.metadata\n","  Using cached pydantic-2.11.1-py3-none-any.whl.metadata (63 kB)\n","Collecting pydantic-settings==2.8.1 (from -r requirements.txt (line 61))\n","  Obtaining dependency information for pydantic-settings==2.8.1 from https://files.pythonhosted.org/packages/0b/53/a64f03044927dc47aafe029c42a5b7aabc38dfb813475e0e1bf71c4a59d0/pydantic_settings-2.8.1-py3-none-any.whl.metadata\n","  Using cached pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n","Collecting pydantic_core==2.33.0 (from -r requirements.txt (line 62))\n","  Obtaining dependency information for pydantic_core==2.33.0 from https://files.pythonhosted.org/packages/42/b4/0bba8412fd242729feeb80e7152e24f0e1a1c19f4121ca3d4a307f4e6222/pydantic_core-2.33.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n","  Using cached pydantic_core-2.33.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.8 kB)\n","Requirement already satisfied: Pygments==2.19.1 in /Users/jewel/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from -r requirements.txt (line 63)) (2.19.1)\n","Requirement already satisfied: python-dateutil==2.9.0.post0 in /Users/jewel/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from -r requirements.txt (line 64)) (2.9.0.post0)\n","Collecting python-dotenv==1.1.0 (from -r requirements.txt (line 65))\n","  Obtaining dependency information for python-dotenv==1.1.0 from https://files.pythonhosted.org/packages/1e/18/98a99ad95133c6a6e2005fe89faedf294a748bd5dc803008059409ac9b1e/python_dotenv-1.1.0-py3-none-any.whl.metadata\n","  Using cached python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n","Collecting PyYAML==6.0.2 (from -r requirements.txt (line 66))\n","  Obtaining dependency information for PyYAML==6.0.2 from https://files.pythonhosted.org/packages/8b/62/b9faa998fd185f65c1371643678e4d58254add437edb764a08c5a98fb986/PyYAML-6.0.2-cp311-cp311-macosx_11_0_arm64.whl.metadata\n","  Using cached PyYAML-6.0.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.1 kB)\n","Collecting pyzmq==26.3.0 (from -r requirements.txt (line 67))\n","  Obtaining dependency information for pyzmq==26.3.0 from https://files.pythonhosted.org/packages/22/75/774e9a4a4291864dd37a03a7bfaf46a82d61cd36c16edd33a5739ad49be3/pyzmq-26.3.0-cp311-cp311-macosx_10_15_universal2.whl.metadata\n","  Using cached pyzmq-26.3.0-cp311-cp311-macosx_10_15_universal2.whl.metadata (6.2 kB)\n","Collecting requests==2.32.3 (from -r requirements.txt (line 68))\n","  Obtaining dependency information for requests==2.32.3 from https://files.pythonhosted.org/packages/f9/9b/335f9764261e915ed497fcdeb11df5dfd6f7bf257d4a6a2a686d80da4d54/requests-2.32.3-py3-none-any.whl.metadata\n","  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n","Collecting requests-toolbelt==1.0.0 (from -r requirements.txt (line 69))\n","  Obtaining dependency information for requests-toolbelt==1.0.0 from https://files.pythonhosted.org/packages/3f/51/d4db610ef29373b879047326cbf6fa98b6c1969d6f6dc423279de2b1be2c/requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata\n","  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: six==1.17.0 in /Users/jewel/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from -r requirements.txt (line 70)) (1.17.0)\n","Collecting sniffio==1.3.1 (from -r requirements.txt (line 71))\n","  Obtaining dependency information for sniffio==1.3.1 from https://files.pythonhosted.org/packages/e9/44/75a9c9421471a6c4805dbf2356f7c181a29c1879239abab1ea2cc8f38b40/sniffio-1.3.1-py3-none-any.whl.metadata\n","  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n","Collecting SQLAlchemy==2.0.40 (from -r requirements.txt (line 72))\n","  Obtaining dependency information for SQLAlchemy==2.0.40 from https://files.pythonhosted.org/packages/77/0f/dcf7bba95f847aec72f638750747b12d37914f71c8cc7c133cf326ab945c/sqlalchemy-2.0.40-cp311-cp311-macosx_11_0_arm64.whl.metadata\n","  Using cached sqlalchemy-2.0.40-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.6 kB)\n","Requirement already satisfied: stack-data==0.6.3 in /Users/jewel/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from -r requirements.txt (line 73)) (0.6.3)\n","Collecting tenacity==9.1.2 (from -r requirements.txt (line 74))\n","  Obtaining dependency information for tenacity==9.1.2 from https://files.pythonhosted.org/packages/e5/30/643397144bfbfec6f6ef821f36f33e57d35946c44a2352d3c9f0ae847619/tenacity-9.1.2-py3-none-any.whl.metadata\n","  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n","Requirement already satisfied: tornado==6.4.2 in /Users/jewel/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from -r requirements.txt (line 75)) (6.4.2)\n","Collecting tqdm==4.67.1 (from -r requirements.txt (line 76))\n","  Obtaining dependency information for tqdm==4.67.1 from https://files.pythonhosted.org/packages/d0/30/dc54f88dd4a2b5dc8a0279bdd7270e735851848b762aeb1c1184ed1f6b14/tqdm-4.67.1-py3-none-any.whl.metadata\n","  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n","Requirement already satisfied: traitlets==5.14.3 in /Users/jewel/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from -r requirements.txt (line 77)) (5.14.3)\n","Collecting typing-inspect==0.9.0 (from -r requirements.txt (line 78))\n","  Obtaining dependency information for typing-inspect==0.9.0 from https://files.pythonhosted.org/packages/65/f3/107a22063bf27bdccf2024833d3445f4eea42b2e598abfbd46f6a63b6cb0/typing_inspect-0.9.0-py3-none-any.whl.metadata\n","  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n","Collecting typing-inspection==0.4.0 (from -r requirements.txt (line 79))\n","  Obtaining dependency information for typing-inspection==0.4.0 from https://files.pythonhosted.org/packages/31/08/aa4fdfb71f7de5176385bd9e90852eaf6b5d622735020ad600f2bab54385/typing_inspection-0.4.0-py3-none-any.whl.metadata\n","  Using cached typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n","Collecting typing_extensions==4.13.0 (from -r requirements.txt (line 80))\n","  Obtaining dependency information for typing_extensions==4.13.0 from https://files.pythonhosted.org/packages/e0/86/39b65d676ec5732de17b7e3c476e45bb80ec64eb50737a8dce1a4178aba1/typing_extensions-4.13.0-py3-none-any.whl.metadata\n","  Using cached typing_extensions-4.13.0-py3-none-any.whl.metadata (3.0 kB)\n","Collecting urllib3==2.3.0 (from -r requirements.txt (line 81))\n","  Obtaining dependency information for urllib3==2.3.0 from https://files.pythonhosted.org/packages/c8/19/4ec628951a74043532ca2cf5d97b7b14863931476d117c471e8e2b1eb39f/urllib3-2.3.0-py3-none-any.whl.metadata\n","  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n","Requirement already satisfied: wcwidth==0.2.13 in /Users/jewel/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from -r requirements.txt (line 82)) (0.2.13)\n","Collecting xxhash==3.5.0 (from -r requirements.txt (line 83))\n","  Obtaining dependency information for xxhash==3.5.0 from https://files.pythonhosted.org/packages/8c/0c/7c3bc6d87e5235672fcc2fb42fd5ad79fe1033925f71bf549ee068c7d1ca/xxhash-3.5.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n","  Using cached xxhash-3.5.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (12 kB)\n","Collecting yarl==1.18.3 (from -r requirements.txt (line 84))\n","  Obtaining dependency information for yarl==1.18.3 from https://files.pythonhosted.org/packages/5a/a1/205ab51e148fdcedad189ca8dd587794c6f119882437d04c33c01a75dece/yarl-1.18.3-cp311-cp311-macosx_11_0_arm64.whl.metadata\n","  Using cached yarl-1.18.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (69 kB)\n","Collecting zstandard==0.23.0 (from -r requirements.txt (line 85))\n","  Obtaining dependency information for zstandard==0.23.0 from https://files.pythonhosted.org/packages/e8/46/66d5b55f4d737dd6ab75851b224abf0afe5774976fe511a54d2eb9063a41/zstandard-0.23.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n","  Using cached zstandard-0.23.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (3.0 kB)\n","Requirement already satisfied: appnope in /Users/jewel/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from ipykernel==6.29.5->-r requirements.txt (line 23)) (0.1.4)\n","\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'multidict' candidate (version 6.3.1 at https://files.pythonhosted.org/packages/cf/f7/6b0a993d3d48ca9a4d5ce008b1789a527dbbddaaf37a6612cd620bd22a85/multidict-6.3.1-cp311-cp311-macosx_11_0_arm64.whl (from https://pypi.org/simple/multidict/) (requires-python:>=3.9))\n","Reason for being yanked: Memory Leak: https://github.com/aio-libs/multidict/issues/1117\u001b[0m\u001b[33m\n","\u001b[0mUsing cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n","Using cached aiohttp-3.11.16-cp311-cp311-macosx_11_0_arm64.whl (456 kB)\n","Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n","Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n","Using cached anyio-4.9.0-py3-none-any.whl (100 kB)\n","Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n","Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n","Using cached charset_normalizer-3.4.1-cp311-cp311-macosx_10_9_universal2.whl (194 kB)\n","Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n","Using cached debugpy-1.8.13-cp311-cp311-macosx_14_0_universal2.whl (2.2 MB)\n","Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n","Using cached frozenlist-1.5.0-cp311-cp311-macosx_11_0_arm64.whl (52 kB)\n","Using cached greenlet-3.1.1-cp311-cp311-macosx_11_0_universal2.whl (272 kB)\n","Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n","Using cached httpcore-1.0.7-py3-none-any.whl (78 kB)\n","Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n","Using cached httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n","Using cached idna-3.10-py3-none-any.whl (70 kB)\n","Using cached ipython-9.0.2-py3-none-any.whl (600 kB)\n","Using cached jiter-0.9.0-cp311-cp311-macosx_11_0_arm64.whl (320 kB)\n","Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n","Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n","Using cached langchain-0.3.18-py3-none-any.whl (1.0 MB)\n","Using cached langchain_community-0.3.17-py3-none-any.whl (2.5 MB)\n","Using cached langchain_core-0.3.49-py3-none-any.whl (420 kB)\n","Using cached langchain_nvidia_ai_endpoints-0.3.9-py3-none-any.whl (41 kB)\n","Using cached langchain_text_splitters-0.3.6-py3-none-any.whl (31 kB)\n","Using cached langgraph-0.3.22-py3-none-any.whl (139 kB)\n","Using cached langgraph_checkpoint-2.0.23-py3-none-any.whl (41 kB)\n","Using cached langgraph_prebuilt-0.1.7-py3-none-any.whl (25 kB)\n","Using cached langgraph_sdk-0.1.60-py3-none-any.whl (47 kB)\n","Using cached langsmith-0.3.22-py3-none-any.whl (352 kB)\n","Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n","Using cached multidict-6.3.1-cp311-cp311-macosx_11_0_arm64.whl (36 kB)\n","Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Using cached numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl (14.0 MB)\n","Using cached openai-1.70.0-py3-none-any.whl (599 kB)\n","Using cached orjson-3.10.16-cp311-cp311-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (249 kB)\n","Using cached ormsgpack-1.9.1-cp311-cp311-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl (382 kB)\n","Using cached packaging-24.2-py3-none-any.whl (65 kB)\n","Using cached prompt_toolkit-3.0.50-py3-none-any.whl (387 kB)\n","Using cached propcache-0.3.1-cp311-cp311-macosx_11_0_arm64.whl (45 kB)\n","Using cached pydantic-2.11.1-py3-none-any.whl (442 kB)\n","Using cached pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n","Using cached pydantic_core-2.33.0-cp311-cp311-macosx_11_0_arm64.whl (1.9 MB)\n","Using cached python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n","Using cached PyYAML-6.0.2-cp311-cp311-macosx_11_0_arm64.whl (172 kB)\n","Using cached pyzmq-26.3.0-cp311-cp311-macosx_10_15_universal2.whl (1.3 MB)\n","Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n","Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n","Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n","Using cached sqlalchemy-2.0.40-cp311-cp311-macosx_11_0_arm64.whl (2.1 MB)\n","Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n","Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n","Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Using cached typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n","Using cached typing_extensions-4.13.0-py3-none-any.whl (45 kB)\n","Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n","Using cached xxhash-3.5.0-cp311-cp311-macosx_11_0_arm64.whl (30 kB)\n","Using cached yarl-1.18.3-cp311-cp311-macosx_11_0_arm64.whl (92 kB)\n","Using cached zstandard-0.23.0-cp311-cp311-macosx_11_0_arm64.whl (633 kB)\n","Installing collected packages: zstandard, xxhash, urllib3, typing_extensions, tqdm, tenacity, sniffio, pyzmq, PyYAML, python-dotenv, propcache, prompt_toolkit, packaging, ormsgpack, orjson, numpy, mypy-extensions, multidict, jsonpointer, jiter, idna, httpx-sse, h11, greenlet, frozenlist, distro, debugpy, charset-normalizer, certifi, attrs, annotated-types, aiohappyeyeballs, yarl, typing-inspection, typing-inspect, SQLAlchemy, requests, pydantic_core, marshmallow, jsonpatch, ipython, httpcore, anyio, aiosignal, requests-toolbelt, pydantic, httpx, dataclasses-json, aiohttp, pydantic-settings, openai, langsmith, langgraph-sdk, langchain-core, langgraph-checkpoint, langchain-text-splitters, langchain-nvidia-ai-endpoints, langgraph-prebuilt, langchain, langgraph, langchain-community\n","  Attempting uninstall: typing_extensions\n","    Found existing installation: typing_extensions 4.13.2\n","    Uninstalling typing_extensions-4.13.2:\n","      Successfully uninstalled typing_extensions-4.13.2\n","  Attempting uninstall: pyzmq\n","    Found existing installation: pyzmq 26.4.0\n","    Uninstalling pyzmq-26.4.0:\n","      Successfully uninstalled pyzmq-26.4.0\n","  Attempting uninstall: prompt_toolkit\n","    Found existing installation: prompt_toolkit 3.0.51\n","    Uninstalling prompt_toolkit-3.0.51:\n","      Successfully uninstalled prompt_toolkit-3.0.51\n","  Attempting uninstall: packaging\n","    Found existing installation: packaging 25.0\n","    Uninstalling packaging-25.0:\n","      Successfully uninstalled packaging-25.0\n","  Attempting uninstall: debugpy\n","    Found existing installation: debugpy 1.8.14\n","    Uninstalling debugpy-1.8.14:\n","      Successfully uninstalled debugpy-1.8.14\n","  Attempting uninstall: ipython\n","    Found existing installation: ipython 9.2.0\n","    Uninstalling ipython-9.2.0:\n","      Successfully uninstalled ipython-9.2.0\n","Successfully installed PyYAML-6.0.2 SQLAlchemy-2.0.40 aiohappyeyeballs-2.6.1 aiohttp-3.11.16 aiosignal-1.3.2 annotated-types-0.7.0 anyio-4.9.0 attrs-25.3.0 certifi-2025.1.31 charset-normalizer-3.4.1 dataclasses-json-0.6.7 debugpy-1.8.13 distro-1.9.0 frozenlist-1.5.0 greenlet-3.1.1 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 httpx-sse-0.4.0 idna-3.10 ipython-9.0.2 jiter-0.9.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.18 langchain-community-0.3.17 langchain-core-0.3.49 langchain-nvidia-ai-endpoints-0.3.9 langchain-text-splitters-0.3.6 langgraph-0.3.22 langgraph-checkpoint-2.0.23 langgraph-prebuilt-0.1.7 langgraph-sdk-0.1.60 langsmith-0.3.22 marshmallow-3.26.1 multidict-6.3.1 mypy-extensions-1.0.0 numpy-1.26.4 openai-1.70.0 orjson-3.10.16 ormsgpack-1.9.1 packaging-24.2 prompt_toolkit-3.0.50 propcache-0.3.1 pydantic-2.11.1 pydantic-settings-2.8.1 pydantic_core-2.33.0 python-dotenv-1.1.0 pyzmq-26.3.0 requests-2.32.3 requests-toolbelt-1.0.0 sniffio-1.3.1 tenacity-9.1.2 tqdm-4.67.1 typing-inspect-0.9.0 typing-inspection-0.4.0 typing_extensions-4.13.0 urllib3-2.3.0 xxhash-3.5.0 yarl-1.18.3 zstandard-0.23.0\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"]}],"source":["!pip install -r requirements.txt"]},{"cell_type":"markdown","metadata":{"id":"LaRm8Bz-1qfQ"},"source":["For running the notebook on colab:"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"MJBz5XW81mGZ"},"outputs":[{"name":"stdout","output_type":"stream","text":["zsh:1: 0.2.0 not found\n"]}],"source":["# !pip install langgraph>=0.2.0 langchain==0.3.18 langchain-community==0.3.17 langchain-core==0.3.49 langchain-nvidia-ai-endpoints==0.3.9 langchain-text-splitters==0.3.6\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1127,"status":"ok","timestamp":1742261272714,"user":{"displayName":"Darren Tan SG","userId":"07785499131391784730"},"user_tz":-480},"id":"iZZjCq_41DTF","outputId":"8d671ad5-2a34-4874-d8f7-08135a905bfe"},"outputs":[{"name":"stdout","output_type":"stream","text":["Installed kernelspec venv_jup in /Users/jewel/Library/Jupyter/kernels/venv_jup\n"]}],"source":["!ipython kernel install --user --name=venv_jup"]},{"cell_type":"markdown","metadata":{},"source":["Import necessary packages"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"81Yd7IG41DTF"},"outputs":[],"source":["import os\n","import json\n","from langchain_nvidia_ai_endpoints import ChatNVIDIA\n","from typing import Annotated\n","from typing_extensions import TypedDict\n","from langgraph.graph.message import add_messages\n","\n","from langgraph.graph import StateGraph, START, END\n","from langgraph.checkpoint.memory import MemorySaver\n","\n","from langchain_community.tools.tavily_search import TavilySearchResults\n","from langgraph.prebuilt import create_react_agent"]},{"cell_type":"markdown","metadata":{"id":"S74QZqvg83KA"},"source":["Loads keys for:\n","1. NVIDIA NIMs\n","2. LangSmith (for logging and dashboards)\n","3. Tavily (web search)"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# os.environ[\"NVIDIA_API_KEY\"] = \"<INSERT NVIDIA API KEY>\"\n","\n","os.environ[\"NVIDIA_API_KEY\"] = \"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\""]},{"cell_type":"markdown","metadata":{"id":"UgapcW7_1DTF"},"source":["Conversation history can be accessed in the Langsmith/Langchain dashboard when using this endpoint"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"oXbeKhqm1DTF"},"outputs":[{"ename":"NameError","evalue":"name 'os' is not defined","output_type":"error","traceback":["\u001b[31m---------------------------------------------------------------------------\u001b[39m","\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)","\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# os.environ[\"LANGCHAIN_ENDPOINT\"]=\"https://api.smith.langchain.com\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# os.environ[\"LANGSMITH_API_KEY\"]=\"<INSERT LANGSMITH API KEY>\"\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# os.environ[\"LANGCHAIN_PROJECT\"]=\"<INSERT ANY PROJECT NAME>\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mos\u001b[49m.environ[\u001b[33m\"\u001b[39m\u001b[33mLANGCHAIN_TRACING_V2\u001b[39m\u001b[33m\"\u001b[39m]=\u001b[33m\"\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      7\u001b[39m os.environ[\u001b[33m\"\u001b[39m\u001b[33mLANGCHAIN_ENDPOINT\u001b[39m\u001b[33m\"\u001b[39m]=\u001b[33m\"\u001b[39m\u001b[33mhttps://api.smith.langchain.com\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      8\u001b[39m os.environ[\u001b[33m\"\u001b[39m\u001b[33mLANGSMITH_API_KEY\u001b[39m\u001b[33m\"\u001b[39m]=\u001b[33m\"\u001b[39m\u001b[33mlsv2_pt_7f3e3cf2c65c46bc8e5fc1bb59f8208c_91fa9b2afa\u001b[39m\u001b[33m\"\u001b[39m\n","\u001b[31mNameError\u001b[39m: name 'os' is not defined"]}],"source":["# os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n","# os.environ[\"LANGCHAIN_ENDPOINT\"]=\"https://api.smith.langchain.com\"\n","# os.environ[\"LANGSMITH_API_KEY\"]=\"<INSERT LANGSMITH API KEY>\"\n","# os.environ[\"LANGCHAIN_PROJECT\"]=\"<INSERT ANY PROJECT NAME>\"\n","\n","os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n","os.environ[\"LANGCHAIN_ENDPOINT\"]=\"https://api.smith.langchain.com\"\n","os.environ[\"LANGSMITH_API_KEY\"]=\"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\"\n","os.environ[\"LANGCHAIN_PROJECT\"]=\"project_name_1\"\n","\n","\n","# os.environ[\"TAVILY_API_KEY\"]=\"<INSERT TAVILY API KEY>\"\n","\n","os.environ[\"TAVILY_API_KEY\"]=\"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\""]},{"cell_type":"markdown","metadata":{"id":"ahSZHpzG9rLr"},"source":["For more information on LangGraph visit their [Quickstart Guide](https://langchain-ai.github.io/langgraph/tutorials/introduction/#requirements)."]},{"cell_type":"markdown","metadata":{"id":"ZVeuJp021DTG"},"source":["## LLM Initialisation"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"kbl46gwz1DTG"},"outputs":[],"source":["# Generate response\n","llm = ChatNVIDIA(\n","    model=\"nvdev/meta/llama-3.1-70b-instruct\",\n","    nvidia_api_key=os.environ[\"NVIDIA_API_KEY\"],\n",")"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1742261272820,"user":{"displayName":"Darren Tan SG","userId":"07785499131391784730"},"user_tz":-480},"id":"3Uqo64x41DTG","outputId":"f9417e5f-91ba-4667-fe98-0869bf1eb1d3"},"outputs":[{"data":{"text/plain":["ChatNVIDIA(base_url='https://integrate.api.nvidia.com/v1', model='nvdev/meta/llama-3.1-70b-instruct')"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["llm"]},{"cell_type":"markdown","metadata":{"id":"wzxLLOdi1DTG"},"source":["# üõ†Ô∏è First Capability: Memory-Augmented Chatbot (Persistent Memory with LangGraph)\n","\n","Exploring implementing conversational memory into the LangGraph graphing framework.\n","\n","Let's build a chatbot that remembers user input (e.g., name), using LangGraph and MemorySaver.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"2nqDAbZ4AUIT"},"source":["This `State` class is a typed dictionary for storing a conversation‚Äôs history. The `messages` key is annotated so new AI or user messages get appended, enabling a memory-based ReAct agent to retain context and maintain an ongoing conversation."]},{"cell_type":"code","execution_count":7,"metadata":{"id":"VIzUeSQH1DTG"},"outputs":[],"source":["class State(TypedDict):\n","    messages: Annotated[list, add_messages]"]},{"cell_type":"markdown","metadata":{"id":"PSzBUTJpyYZ4"},"source":["We‚Äôre creating a graph that leverages our `State` class to remember all user and AI messages"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"nJB9iASd1DTG"},"outputs":[],"source":["graph_builder = StateGraph(State)"]},{"cell_type":"markdown","metadata":{"id":"Ks0zuwYK1DTH"},"source":["Define a function that takes the current conversation state and returns a new AI-generated message by invoking the language model on the existing message history.\n"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"ygQFx_Rp1DTH"},"outputs":[],"source":["def chatbot(state: State):\n","    return {\"messages\": [llm.invoke(state[\"messages\"])]}"]},{"cell_type":"markdown","metadata":{"id":"INXk1Cpy1DTH"},"source":["These lines add the chatbot function as a node in the LangGraph workflow, then define the execution flow to start at START, run the chatbot node, and proceed to END after the chatbot generates a response."]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":45,"status":"ok","timestamp":1742261272919,"user":{"displayName":"Darren Tan SG","userId":"07785499131391784730"},"user_tz":-480},"id":"cl07YsnI1DTH","outputId":"0d4cdc67-e03b-4a55-cf58-1e6551915727"},"outputs":[{"data":{"text/plain":["<langgraph.graph.state.StateGraph at 0x122471850>"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# Adding the chatbot node to our graph with a unique name.\n","graph_builder.add_node(\"chatbot\", chatbot)\n","\n","# Defining the flow: Start ‚Üí Chatbot\n","graph_builder.add_edge(START, \"chatbot\")\n","\n","# After the chatbot node, the workflow goes to the End.\n","graph_builder.add_edge(\"chatbot\", END)"]},{"cell_type":"markdown","metadata":{"id":"2BWLTzZD1DTH"},"source":["Initializes a `MemorySaver` to persist conversation state between interactions and compiles the LangGraph workflow with this memory checkpointing, enabling the agent to retain and update its message history across turns."]},{"cell_type":"code","execution_count":11,"metadata":{"id":"CO-gWMIs1DTH"},"outputs":[],"source":["memory = MemorySaver()\n","graph = graph_builder.compile(checkpointer=memory)"]},{"cell_type":"markdown","metadata":{"id":"EVPETjj82kMJ"},"source":["This code initializes a unique session (thread_id), feeds the user's message into the LangGraph workflow, streams the AI's response in real time, and prints the latest message in the conversation"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1264,"status":"ok","timestamp":1742261274188,"user":{"displayName":"Darren Tan SG","userId":"07785499131391784730"},"user_tz":-480},"id":"yE0wH2Su1DTI","outputId":"371061df-4f25-45ce-cf35-7b9a7ee8030d"},"outputs":[{"name":"stdout","output_type":"stream","text":["================================\u001b[1m Human Message \u001b[0m=================================\n","\n","Hi! My name is Will\n","==================================\u001b[1m Ai Message \u001b[0m==================================\n","\n","Nice to meet you, Will! Is there something I can help you with or would you like to chat for a bit?\n"]}],"source":["# Identifier for the specific chat\n","thread_id = \"memory_only_2\"\n","\n","config = {\"configurable\": {\"thread_id\": thread_id}}\n","\n","user_input = \"Hi! My name is Will\"\n","\n","# Initial state (with user's message) is fed into the workflow\n","# Chatbot node takes the current conversation and generates a response using llm.invoke, and then appends that response to \"messages\" list\n","events = graph.stream(\n","    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n","    config,\n","    stream_mode=\"values\",\n",")\n","for event in events:\n","    event[\"messages\"][-1].pretty_print()"]},{"cell_type":"markdown","metadata":{},"source":["This code takes different kinds of objects‚Äîlike AI or user messages‚Äîand turns them into easy-to-read JSON so we can see what‚Äôs going on inside the chatbot‚Äôs memory."]},{"cell_type":"code","execution_count":13,"metadata":{"id":"yVYiJv3k1DTI"},"outputs":[],"source":["# # Function to format the output into pretty print\n","# # Defining custom JSON serialisable to print the indents for the JSON response\n","# def custom_serializer(obj):\n","#     # If the object has a method to convert to a dict, use it.\n","#     if hasattr(obj, \"dict\"):\n","#         return obj.dict()\n","#     # If it's a HumanMessage-like object, try to convert it manually.\n","#     # Adjust the attribute names as needed for your specific object.\n","#     if hasattr(obj, \"role\") and hasattr(obj, \"content\"):\n","#         return {\"role\": obj.role, \"content\": obj.content}\n","#     # Fallback: convert to string.\n","#     return str(obj)\n","\n","def custom_serializer(obj):\n","    \"\"\"\n","    Converts the given object into a JSON-serializable dictionary or string.\n","    1. If the object has a dict() method, use that.\n","    2. If it has 'role' and 'content' attributes (Langchain messages), map them to a dict.\n","    3. Otherwise, return its string representation.\n","    \"\"\"\n","    if hasattr(obj, \"dict\"):\n","        return obj.dict()\n","    if hasattr(obj, \"role\") and hasattr(obj, \"content\"):\n","        return {\"role\": obj.role, \"content\": obj.content}\n","    return str(obj)"]},{"cell_type":"markdown","metadata":{"id":"T2ZJ3WLi1DTI"},"source":["Showcasing the conversational memory property as it is able to remember the user's name.\n","\n","Why this works:\n","- MemorySaver stores messages. The LLM sees the whole conversation and answers accordingly."]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1259,"status":"ok","timestamp":1742261275454,"user":{"displayName":"Darren Tan SG","userId":"07785499131391784730"},"user_tz":-480},"id":"RLq3Y3Kv1DTI","outputId":"589975c5-2c21-4cb8-87cf-ad2ca10a340e"},"outputs":[{"name":"stdout","output_type":"stream","text":["================================\u001b[1m Human Message \u001b[0m=================================\n","\n","Remember my name?\n","==================================\u001b[1m Ai Message \u001b[0m==================================\n","\n","Your name is Will. I'll remember it for our conversation, so feel free to forget and have a nice chat.\n"]}],"source":["user_input = \"Remember my name?\"\n","\n","events = graph.stream(\n","    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n","    config,\n","    stream_mode=\"values\",\n",")\n","for event in events:\n","    event[\"messages\"][-1].pretty_print()"]},{"cell_type":"markdown","metadata":{"id":"WqtFqAzO1DTI"},"source":["### Explainability into how the state changes\n","\n","`messages` contains the conversational history as a list of dictionaries, with each **content** key storing the message sent by the AI or human. By looking into the memory of the current conversation (`\"thread_id\": memory_only`), we can observe that the list of AI and human messages are the same ones we've seen before."]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1742261275456,"user":{"displayName":"Darren Tan SG","userId":"07785499131391784730"},"user_tz":-480},"id":"CI8ZAdNF1DTI","outputId":"e996bc1c-f443-4f22-d13a-92421cfb1976"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","====================== What is happening behind the scenes:======================\n","{\n","  \"v\": 2,\n","  \"ts\": \"2025-05-08T06:53:47.232764+00:00\",\n","  \"id\": \"1f02bd93-0a25-641e-8004-ca6cb44da52a\",\n","  \"channel_versions\": {\n","    \"__start__\": \"00000000000000000000000000000005.0.5455720153875686\",\n","    \"messages\": \"00000000000000000000000000000006.0.8058260632204819\",\n","    \"branch:to:chatbot\": \"00000000000000000000000000000006.0.3594041242282897\"\n","  },\n","  \"versions_seen\": {\n","    \"__input__\": {},\n","    \"__start__\": {\n","      \"__start__\": \"00000000000000000000000000000004.0.5037110255252699\"\n","    },\n","    \"chatbot\": {\n","      \"branch:to:chatbot\": \"00000000000000000000000000000005.0.310394043256624\"\n","    }\n","  },\n","  \"channel_values\": {\n","    \"messages\": [\n","      {\n","        \"content\": \"Hi! My name is Will\",\n","        \"additional_kwargs\": {},\n","        \"response_metadata\": {},\n","        \"type\": \"human\",\n","        \"name\": null,\n","        \"id\": \"9a4ff422-582e-4844-9253-5fb86fca49e1\",\n","        \"example\": false\n","      },\n","      {\n","        \"content\": \"Nice to meet you, Will! Is there something I can help you with or would you like to chat for a bit?\",\n","        \"additional_kwargs\": {},\n","        \"response_metadata\": {\n","          \"role\": \"assistant\",\n","          \"content\": \"Nice to meet you, Will! Is there something I can help you with or would you like to chat for a bit?\",\n","          \"token_usage\": {\n","            \"prompt_tokens\": 16,\n","            \"total_tokens\": 41,\n","            \"completion_tokens\": 25\n","          },\n","          \"finish_reason\": \"stop\",\n","          \"model_name\": \"nvdev/meta/llama-3.1-70b-instruct\"\n","        },\n","        \"type\": \"ai\",\n","        \"name\": null,\n","        \"id\": \"run-6de1c960-3ac5-405f-9670-38461a7865ba-0\",\n","        \"example\": false,\n","        \"tool_calls\": [],\n","        \"invalid_tool_calls\": [],\n","        \"usage_metadata\": {\n","          \"input_tokens\": 16,\n","          \"output_tokens\": 25,\n","          \"total_tokens\": 41\n","        },\n","        \"role\": \"assistant\"\n","      },\n","      {\n","        \"content\": \"Remember my name?\",\n","        \"additional_kwargs\": {},\n","        \"response_metadata\": {},\n","        \"type\": \"human\",\n","        \"name\": null,\n","        \"id\": \"2c36bf1c-1e46-40e1-a93c-1f08d2f7318d\",\n","        \"example\": false\n","      },\n","      {\n","        \"content\": \"Your name is Will. I'll remember it for our conversation, so feel free to forget and have a nice chat.\",\n","        \"additional_kwargs\": {},\n","        \"response_metadata\": {\n","          \"role\": \"assistant\",\n","          \"content\": \"Your name is Will. I'll remember it for our conversation, so feel free to forget and have a nice chat.\",\n","          \"token_usage\": {\n","            \"prompt_tokens\": 55,\n","            \"total_tokens\": 79,\n","            \"completion_tokens\": 24\n","          },\n","          \"finish_reason\": \"stop\",\n","          \"model_name\": \"nvdev/meta/llama-3.1-70b-instruct\"\n","        },\n","        \"type\": \"ai\",\n","        \"name\": null,\n","        \"id\": \"run-3025ac2e-8774-411f-a614-df26dc2dba28-0\",\n","        \"example\": false,\n","        \"tool_calls\": [],\n","        \"invalid_tool_calls\": [],\n","        \"usage_metadata\": {\n","          \"input_tokens\": 55,\n","          \"output_tokens\": 24,\n","          \"total_tokens\": 79\n","        },\n","        \"role\": \"assistant\"\n","      }\n","    ]\n","  },\n","  \"pending_sends\": []\n","}\n"]}],"source":["print(\"\\n====================== What is happening behind the scenes:======================\")\n","print(json.dumps(memory.get(config), indent=2, default=custom_serializer))"]},{"cell_type":"markdown","metadata":{"id":"7rYuQela1DTI"},"source":["Let's take a closer look into how `messages` changes throughout the conversation.\n","\n","Running the cell below executes 2 runs of the conversation which includes logging of `messages` to study its changes.\n","\n","<details>\n","  <summary><strong>More info</strong></summary>\n","\n","Similar to the previous `chatbot` function built before, `chatbot_with_logging` is built like this:\n","\n","- The LLM is invoked with the current state of `messages`.\n","\n","- **new_message**: Single AI message you receive based on the conversational memory\n","\n","- The **new_message** will be appended to `messages` due to the previously declared `add_messages` annotation in State.\n","\n","</details>"]},{"cell_type":"markdown","metadata":{},"source":["![image](img/flowchart.png)"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1118,"status":"ok","timestamp":1742261276572,"user":{"displayName":"Darren Tan SG","userId":"07785499131391784730"},"user_tz":-480},"id":"qnUUcYAF1DTI","outputId":"4d456026-456c-4f19-9b36-e59b0459e101"},"outputs":[{"name":"stdout","output_type":"stream","text":["================================\u001b[1m Human Message \u001b[0m=================================\n","\n","Hi! My name is Will\n","\n","\n","Current conversation history: [HumanMessage(content='Hi! My name is Will', additional_kwargs={}, response_metadata={}, id='c0e7da92-0c83-42a2-b450-e5effbc2af91')]\n","\n","\n","New message from LLM:\n","{\n","  \"content\": \"Nice to meet you, Will! Is there something I can help you with or would you like to chat for a bit?\",\n","  \"additional_kwargs\": {},\n","  \"response_metadata\": {\n","    \"role\": \"assistant\",\n","    \"content\": \"Nice to meet you, Will! Is there something I can help you with or would you like to chat for a bit?\",\n","    \"token_usage\": {\n","      \"prompt_tokens\": 16,\n","      \"total_tokens\": 41,\n","      \"completion_tokens\": 25\n","    },\n","    \"finish_reason\": \"stop\",\n","    \"model_name\": \"nvdev/meta/llama-3.1-70b-instruct\"\n","  },\n","  \"type\": \"ai\",\n","  \"name\": null,\n","  \"id\": \"run-e7550a04-02c0-44a8-af05-2b1e770bc426-0\",\n","  \"example\": false,\n","  \"tool_calls\": [],\n","  \"invalid_tool_calls\": [],\n","  \"usage_metadata\": {\n","    \"input_tokens\": 16,\n","    \"output_tokens\": 25,\n","    \"total_tokens\": 41\n","  },\n","  \"role\": \"assistant\"\n","}\n","\n","\n","==================================\u001b[1m Ai Message \u001b[0m==================================\n","\n","Nice to meet you, Will! Is there something I can help you with or would you like to chat for a bit?\n","================================\u001b[1m Human Message \u001b[0m=================================\n","\n","Remember my name?\n","\n","\n","Current conversation history: [HumanMessage(content='Hi! My name is Will', additional_kwargs={}, response_metadata={}, id='c0e7da92-0c83-42a2-b450-e5effbc2af91'), AIMessage(content='Nice to meet you, Will! Is there something I can help you with or would you like to chat for a bit?', additional_kwargs={}, response_metadata={'role': 'assistant', 'content': 'Nice to meet you, Will! Is there something I can help you with or would you like to chat for a bit?', 'token_usage': {'prompt_tokens': 16, 'total_tokens': 41, 'completion_tokens': 25}, 'finish_reason': 'stop', 'model_name': 'nvdev/meta/llama-3.1-70b-instruct'}, id='run-e7550a04-02c0-44a8-af05-2b1e770bc426-0', usage_metadata={'input_tokens': 16, 'output_tokens': 25, 'total_tokens': 41}, role='assistant'), HumanMessage(content='Remember my name?', additional_kwargs={}, response_metadata={}, id='1b3a42a9-c501-4682-a517-37243c7451d4')]\n","\n","\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[31m---------------------------------------------------------------------------\u001b[39m","\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)","\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 47\u001b[39m\n\u001b[32m     40\u001b[39m user_input_2 = \u001b[33m\"\u001b[39m\u001b[33mRemember my name?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     42\u001b[39m events_2 = graph_with_logging.stream(\n\u001b[32m     43\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [{\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: user_input_2}]},\n\u001b[32m     44\u001b[39m     config,\n\u001b[32m     45\u001b[39m     stream_mode=\u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     46\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevents_2\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpretty_print\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.7/lib/python3.11/site-packages/langgraph/pregel/__init__.py:2325\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[39m\n\u001b[32m   2319\u001b[39m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[32m   2320\u001b[39m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[32m   2321\u001b[39m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[32m   2322\u001b[39m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[32m   2323\u001b[39m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[32m   2324\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m loop.tick(input_keys=\u001b[38;5;28mself\u001b[39m.input_channels):\n\u001b[32m-> \u001b[39m\u001b[32m2325\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2326\u001b[39m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2327\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2328\u001b[39m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2329\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2330\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2331\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2332\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2333\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n","\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.7/lib/python3.11/site-packages/langgraph/pregel/runner.py:158\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[39m\n\u001b[32m    156\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m                \u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    173\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n","\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.7/lib/python3.11/site-packages/langgraph/pregel/retry.py:40\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     38\u001b[39m     task.writes.clear()\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     42\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n","\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.7/lib/python3.11/site-packages/langgraph/utils/runnable.py:606\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    602\u001b[39m config = patch_config(\n\u001b[32m    603\u001b[39m     config, callbacks=run_manager.get_child(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    604\u001b[39m )\n\u001b[32m    605\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m606\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    608\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n","\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.7/lib/python3.11/site-packages/langgraph/utils/runnable.py:371\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    370\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m         ret = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse:\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n","\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mchatbot_with_logging\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCurrent conversation history:\u001b[39m\u001b[33m\"\u001b[39m, state[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m new_message = \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mNew message from LLM:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(json.dumps(new_message, indent=\u001b[32m2\u001b[39m, default=custom_serializer))\n","\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.7/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:307\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    297\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    298\u001b[39m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[32m   (...)\u001b[39m\u001b[32m    302\u001b[39m     **kwargs: Any,\n\u001b[32m    303\u001b[39m ) -> BaseMessage:\n\u001b[32m    304\u001b[39m     config = ensure_config(config)\n\u001b[32m    305\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    306\u001b[39m         ChatGeneration,\n\u001b[32m--> \u001b[39m\u001b[32m307\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    317\u001b[39m     ).message\n","\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.7/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:843\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    835\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    836\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    837\u001b[39m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[32m   (...)\u001b[39m\u001b[32m    840\u001b[39m     **kwargs: Any,\n\u001b[32m    841\u001b[39m ) -> LLMResult:\n\u001b[32m    842\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m843\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.7/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:683\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    680\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[32m    681\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    682\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m683\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    684\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    689\u001b[39m         )\n\u001b[32m    690\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    691\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n","\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.7/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:908\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    906\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    907\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m908\u001b[39m         result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    909\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    910\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    911\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    912\u001b[39m         result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n","\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.7/lib/python3.11/site-packages/langchain_nvidia_ai_endpoints/chat_models.py:382\u001b[39m, in \u001b[36mChatNVIDIA._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    380\u001b[39m inputs, extra_headers = _process_for_vlm(inputs, \u001b[38;5;28mself\u001b[39m._client.model)\n\u001b[32m    381\u001b[39m payload = \u001b[38;5;28mself\u001b[39m._get_payload(inputs=inputs, stop=stop, stream=\u001b[38;5;28;01mFalse\u001b[39;00m, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m382\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_req\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    383\u001b[39m responses, _ = \u001b[38;5;28mself\u001b[39m._client.postprocess(response)\n\u001b[32m    384\u001b[39m \u001b[38;5;28mself\u001b[39m._set_callback_out(responses, run_manager)\n","\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.7/lib/python3.11/site-packages/langchain_nvidia_ai_endpoints/_common.py:473\u001b[39m, in \u001b[36m_NVIDIAClient.get_req\u001b[39m\u001b[34m(self, payload, extra_headers)\u001b[39m\n\u001b[32m    467\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_req\u001b[39m(\n\u001b[32m    468\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    469\u001b[39m     payload: \u001b[38;5;28mdict\u001b[39m = {},\n\u001b[32m    470\u001b[39m     extra_headers: \u001b[38;5;28mdict\u001b[39m = {},\n\u001b[32m    471\u001b[39m ) -> Response:\n\u001b[32m    472\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Post to the API.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m     response, session = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minfer_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    476\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._wait(response, session)\n","\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.7/lib/python3.11/site-packages/langchain_nvidia_ai_endpoints/_common.py:366\u001b[39m, in \u001b[36m_NVIDIAClient._post\u001b[39m\u001b[34m(self, invoke_url, payload, extra_headers)\u001b[39m\n\u001b[32m    357\u001b[39m \u001b[38;5;28mself\u001b[39m.last_inputs = {\n\u001b[32m    358\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33murl\u001b[39m\u001b[33m\"\u001b[39m: invoke_url,\n\u001b[32m    359\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m   (...)\u001b[39m\u001b[32m    363\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mjson\u001b[39m\u001b[33m\"\u001b[39m: payload,\n\u001b[32m    364\u001b[39m }\n\u001b[32m    365\u001b[39m session = \u001b[38;5;28mself\u001b[39m.get_session_fn()\n\u001b[32m--> \u001b[39m\u001b[32m366\u001b[39m \u001b[38;5;28mself\u001b[39m.last_response = response = \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__add_authorization\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlast_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[38;5;28mself\u001b[39m._try_raise(response)\n\u001b[32m    370\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response, session\n","\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.7/lib/python3.11/site-packages/requests/sessions.py:637\u001b[39m, in \u001b[36mSession.post\u001b[39m\u001b[34m(self, url, data, json, **kwargs)\u001b[39m\n\u001b[32m    626\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\u001b[38;5;28mself\u001b[39m, url, data=\u001b[38;5;28;01mNone\u001b[39;00m, json=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m    627\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a POST request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[32m    628\u001b[39m \n\u001b[32m    629\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    634\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m    635\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m637\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.7/lib/python3.11/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n","\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.7/lib/python3.11/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n","\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.7/lib/python3.11/site-packages/requests/adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    664\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n","\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.7/lib/python3.11/site-packages/urllib3/connectionpool.py:789\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    786\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    788\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    801\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    804\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    805\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n","\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.7/lib/python3.11/site-packages/urllib3/connectionpool.py:536\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    534\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m536\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    538\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n","\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.7/lib/python3.11/site-packages/urllib3/connection.py:464\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mresponse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[32m    463\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    467\u001b[39m     assert_header_parsing(httplib_response.msg)\n","\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.7/lib/python3.11/http/client.py:1386\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1385\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1386\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1387\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1388\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n","\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.7/lib/python3.11/http/client.py:325\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    323\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    327\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n","\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.7/lib/python3.11/http/client.py:286\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m.fp.readline(_MAXLINE + \u001b[32m1\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    287\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    288\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n","\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.7/lib/python3.11/socket.py:706\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    704\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    705\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m706\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    708\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n","\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.7/lib/python3.11/ssl.py:1315\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1311\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1312\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1313\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1314\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1315\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1316\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1317\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n","\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.7/lib/python3.11/ssl.py:1167\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1165\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1167\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1168\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1169\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n","\u001b[31mKeyboardInterrupt\u001b[39m: "]}],"source":["def chatbot_with_logging(state: State):\n","    print(\"\\n\")\n","    print(\"Current conversation history:\", state[\"messages\"])\n","    print(\"\\n\")\n","    new_message = llm.invoke(state[\"messages\"])\n","    print(\"New message from LLM:\")\n","    print(json.dumps(new_message, indent=2, default=custom_serializer))\n","    print(\"\\n\")\n","    return {\"messages\": [new_message]}\n","\n","graph_builder_with_logging = StateGraph(State)\n","\n","# Adding the chatbot node to our graph with a unique name.\n","graph_builder_with_logging.add_node(\"chatbot\", chatbot_with_logging)\n","\n","# Defining the flow: Start ‚Üí Chatbot\n","graph_builder_with_logging.add_edge(START, \"chatbot\")\n","\n","# After the chatbot node, the workflow goes to the End.\n","graph_builder_with_logging.add_edge(\"chatbot\", END)\n","\n","memory_with_logging = MemorySaver()\n","graph_with_logging = graph_builder_with_logging.compile(checkpointer=memory_with_logging)\n","\n","# Should be different from the previous in order to get a fresh conversation\n","thread_id = \"memory_only_with_logging_2\"\n","\n","config = {\"configurable\": {\"thread_id\": thread_id}}\n","\n","user_input = \"Hi! My name is Will\"\n","\n","events = graph_with_logging.stream(\n","    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n","    config,\n","    stream_mode=\"values\",\n",")\n","for event in events:\n","    event[\"messages\"][-1].pretty_print()\n","\n","user_input_2 = \"Remember my name?\"\n","\n","events_2 = graph_with_logging.stream(\n","    {\"messages\": [{\"role\": \"user\", \"content\": user_input_2}]},\n","    config,\n","    stream_mode=\"values\",\n",")\n","for event in events_2:\n","    event[\"messages\"][-1].pretty_print()"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1742261276596,"user":{"displayName":"Darren Tan SG","userId":"07785499131391784730"},"user_tz":-480},"id":"psHQDWT01DTI","outputId":"b17d1856-23d3-4b58-c737-38f512be76bb"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","====================== What is happening behind the scenes:======================\n","{\n","  \"v\": 2,\n","  \"ts\": \"2025-04-30T09:32:15.814621+00:00\",\n","  \"id\": \"1f025a60-0e2c-68fa-8004-c865bb2e14a3\",\n","  \"channel_versions\": {\n","    \"__start__\": \"00000000000000000000000000000005.0.3756749851617761\",\n","    \"messages\": \"00000000000000000000000000000006.0.5323631868781991\",\n","    \"branch:to:chatbot\": \"00000000000000000000000000000006.0.31351555008916043\"\n","  },\n","  \"versions_seen\": {\n","    \"__input__\": {},\n","    \"__start__\": {\n","      \"__start__\": \"00000000000000000000000000000004.0.3446049711246755\"\n","    },\n","    \"chatbot\": {\n","      \"branch:to:chatbot\": \"00000000000000000000000000000005.0.9332388485926778\"\n","    }\n","  },\n","  \"channel_values\": {\n","    \"messages\": [\n","      {\n","        \"content\": \"Hi! My name is Will\",\n","        \"additional_kwargs\": {},\n","        \"response_metadata\": {},\n","        \"type\": \"human\",\n","        \"name\": null,\n","        \"id\": \"20f84808-78e8-47f7-b3f2-478e61517f9f\",\n","        \"example\": false\n","      },\n","      {\n","        \"content\": \"Nice to meet you, Will! Is there something I can help you with or would you like to chat for a bit?\",\n","        \"additional_kwargs\": {},\n","        \"response_metadata\": {\n","          \"role\": \"assistant\",\n","          \"content\": \"Nice to meet you, Will! Is there something I can help you with or would you like to chat for a bit?\",\n","          \"token_usage\": {\n","            \"prompt_tokens\": 16,\n","            \"total_tokens\": 41,\n","            \"completion_tokens\": 25\n","          },\n","          \"finish_reason\": \"stop\",\n","          \"model_name\": \"nvdev/meta/llama-3.1-70b-instruct\"\n","        },\n","        \"type\": \"ai\",\n","        \"name\": null,\n","        \"id\": \"run-614b169d-52af-43b1-85cf-08fe77af63c3-0\",\n","        \"example\": false,\n","        \"tool_calls\": [],\n","        \"invalid_tool_calls\": [],\n","        \"usage_metadata\": {\n","          \"input_tokens\": 16,\n","          \"output_tokens\": 25,\n","          \"total_tokens\": 41\n","        },\n","        \"role\": \"assistant\"\n","      },\n","      {\n","        \"content\": \"Remember my name?\",\n","        \"additional_kwargs\": {},\n","        \"response_metadata\": {},\n","        \"type\": \"human\",\n","        \"name\": null,\n","        \"id\": \"04d8b048-ad92-4211-b07d-b8ef57188de5\",\n","        \"example\": false\n","      },\n","      {\n","        \"content\": \"Your name is Will. I'll remember it for our conversation, but don't worry, I don't retain any personal info or memories of our chats after we're done, so it's totally private and secure!\",\n","        \"additional_kwargs\": {},\n","        \"response_metadata\": {\n","          \"role\": \"assistant\",\n","          \"content\": \"Your name is Will. I'll remember it for our conversation, but don't worry, I don't retain any personal info or memories of our chats after we're done, so it's totally private and secure!\",\n","          \"token_usage\": {\n","            \"prompt_tokens\": 55,\n","            \"total_tokens\": 98,\n","            \"completion_tokens\": 43\n","          },\n","          \"finish_reason\": \"stop\",\n","          \"model_name\": \"nvdev/meta/llama-3.1-70b-instruct\"\n","        },\n","        \"type\": \"ai\",\n","        \"name\": null,\n","        \"id\": \"run-0a3b23e1-91ec-4222-b16e-bb9d077bf8ac-0\",\n","        \"example\": false,\n","        \"tool_calls\": [],\n","        \"invalid_tool_calls\": [],\n","        \"usage_metadata\": {\n","          \"input_tokens\": 55,\n","          \"output_tokens\": 43,\n","          \"total_tokens\": 98\n","        },\n","        \"role\": \"assistant\"\n","      }\n","    ]\n","  },\n","  \"pending_sends\": []\n","}\n"]},{"name":"stderr","output_type":"stream","text":["/var/folders/18/95745h4n0hl94h03fr01c1jc0000gn/T/ipykernel_2269/196634802.py:22: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n","  return obj.dict()\n"]}],"source":["print(\"\\n====================== What is happening behind the scenes:======================\")\n","print(json.dumps(memory_with_logging.get(config), indent=2, default=custom_serializer))"]},{"cell_type":"markdown","metadata":{"id":"7AO1U8O95Ux4"},"source":["<summary><strong>What do we observe?</strong></summary>\n","\n","Human and generated AI messages are appended to `messages` in chronological order as a list in HumanMessage or AIMessage Langchain object accordingly.\n","\n","This graph depicts how `messages` changes, which is then stored using `MemorySaver()` by `StateGraph` from LangGraph.\n"]},{"cell_type":"markdown","metadata":{"id":"x5d0f7u41DTI"},"source":["### Optional: Using .invoke instead of .stream\n","\n","Use stream when you would like the output in chunks, usually when displaying the frontend chatbot interactively. Streaming is not apparent in this jupyter notebook implementation."]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2130,"status":"ok","timestamp":1742261278726,"user":{"displayName":"Darren Tan SG","userId":"07785499131391784730"},"user_tz":-480},"id":"zqmli4ro1DTI","outputId":"1719468a-8c38-48c1-fdce-5f8b69ec6a6b"},"outputs":[{"name":"stdout","output_type":"stream","text":["The capital of France is Paris.\n"]}],"source":["thread_id = \"testing_invoke\"\n","\n","config = {\"configurable\": {\"thread_id\": thread_id}}\n","\n","result = graph.invoke(\n","    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the capital of France?\"}]},\n","    config=config,\n",")\n","print(result[\"messages\"][-1].content)"]},{"cell_type":"markdown","metadata":{"id":"6hlX_CTL1DTI"},"source":["# üïµÔ∏è Second Capability: ReAct Agent with Tavily tool (No Memory)\n","\n","Let's now explore how to implement the Tavily web search tool with LangGraph's create_react_agent. No conversational memory will be implemented yet, we will only be executing a single run to showcase the web search capability."]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31561,"status":"ok","timestamp":1742261310300,"user":{"displayName":"Darren Tan SG","userId":"07785499131391784730"},"user_tz":-480},"id":"iMHwPhbD1DTJ","outputId":"d75083c3-cfd5-4cf2-f4d5-e2bdbcb314ae"},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/jewel/.pyenv/versions/3.11.7/lib/python3.11/site-packages/langchain_nvidia_ai_endpoints/chat_models.py:591: UserWarning: Model 'nvdev/meta/llama-3.1-70b-instruct' is not known to support tools. Your tool binding may fail at inference time.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["\n","================================== Ai Message ==================================\n","Based on the search results, here are some tools for education:\n","\n","1. Educational Tools (EduTools) - a portal that centralizes digital resources and applications to support teaching and learning.\n","2. Bloomz - an interactive app that helps teachers and schools share updates, events, and photos with parents securely.\n","3. Plickers - a tool used to assess students' knowledge, assign homework, and record grades.\n","4. Printed materials like textbooks, workbooks, handouts, and worksheets.\n","5. Projectors and screens to display slideshows, videos, animations, and multimedia content.\n","6. Visual aids like posters, charts, graphs, and diagrams.\n","7. Audio-visual materials such as educational videos, documentaries, podcasts, and audio recordings.\n","8. Models, puzzles, blocks, and other hands-on materials, especially in subjects like mathematics and science.\n","9. Video conferencing tools and learning management systems.\n","10. Digital feedback tools.\n","11. Canva - a graphic design platform that empowers educators to create professional-quality educational content.\n","12. Adobe Premiere Pro - a video creation platform that empowers educators to create professional-quality educational content.\n","13. Nearpod - an educational tool for interactive presentations.\n","14. Feedly - an RSS/news reader.\n","15. Khan Academy - an online course library.\n","16. Whereby - a video meeting platform.\n","17. Firefox - a web browser.\n","18. Quizizz - an educational games and testing tool.\n","19. Prezi - an online presentation tool.\n","20. Raindrop - a bookmark manager.\n","21. Descript - an audio and video editing tool.\n","22. Masterclass - a streaming platform for video lessons.\n","23. Outlook - an email client.\n","24. TED Talks - inspirational videos.\n","25. Duolingo - a language learning app.\n","26. Quizlet - an educational games and testing tool.\n","27. Moodle - an open-source learning platform.\n","28. Vimeo - a video hosting and sharing platform.\n","29. Google Classroom - an educational learning platform.\n","30. hihaho - an interactive video tool.\n","\n","These tools can be used to enhance the learning experience for students, engage parents, and support teachers in their instructional endeavors.\n","{\n","  \"messages\": [\n","    {\n","      \"content\": \"What are some tools for education?\",\n","      \"additional_kwargs\": {},\n","      \"response_metadata\": {},\n","      \"type\": \"human\",\n","      \"name\": null,\n","      \"id\": \"3b58ad35-4815-4ac0-9c1c-8d6be564c656\",\n","      \"example\": false\n","    },\n","    {\n","      \"content\": \"\",\n","      \"additional_kwargs\": {\n","        \"tool_calls\": [\n","          {\n","            \"id\": \"chatcmpl-tool-d4b03986ce184a2cb603c27ad80a79af\",\n","            \"type\": \"function\",\n","            \"function\": {\n","              \"name\": \"tavily_search_results_json\",\n","              \"arguments\": \"{\\\"query\\\": \\\"educational tools\\\"}\"\n","            }\n","          }\n","        ]\n","      },\n","      \"response_metadata\": {\n","        \"role\": \"assistant\",\n","        \"content\": null,\n","        \"tool_calls\": [\n","          {\n","            \"id\": \"chatcmpl-tool-d4b03986ce184a2cb603c27ad80a79af\",\n","            \"type\": \"function\",\n","            \"function\": {\n","              \"name\": \"tavily_search_results_json\",\n","              \"arguments\": \"{\\\"query\\\": \\\"educational tools\\\"}\"\n","            }\n","          }\n","        ],\n","        \"token_usage\": {\n","          \"prompt_tokens\": 314,\n","          \"total_tokens\": 330,\n","          \"completion_tokens\": 16\n","        },\n","        \"finish_reason\": \"tool_calls\",\n","        \"model_name\": \"nvdev/meta/llama-3.1-70b-instruct\"\n","      },\n","      \"type\": \"ai\",\n","      \"name\": null,\n","      \"id\": \"run-7292c288-0fdf-47f7-a760-66df10e60f0e-0\",\n","      \"example\": false,\n","      \"tool_calls\": [\n","        {\n","          \"name\": \"tavily_search_results_json\",\n","          \"args\": {\n","            \"query\": \"educational tools\"\n","          },\n","          \"id\": \"chatcmpl-tool-d4b03986ce184a2cb603c27ad80a79af\",\n","          \"type\": \"tool_call\"\n","        }\n","      ],\n","      \"invalid_tool_calls\": [],\n","      \"usage_metadata\": {\n","        \"input_tokens\": 314,\n","        \"output_tokens\": 16,\n","        \"total_tokens\": 330\n","      },\n","      \"role\": \"assistant\"\n","    },\n","    {\n","      \"content\": \"[{\\\"url\\\": \\\"https://educational.tools/\\\", \\\"content\\\": \\\"Educational Tools (\\u00a9 EduTools) is an educational portal that centralizes digital resources and applications to support teaching and learning.\\\"}, {\\\"url\\\": \\\"https://www.ispringsolutions.com/blog/free-teaching-tools\\\", \\\"content\\\": \\\"2. Why are teaching tools needed in education?\\\\nTeaching tools are designed to help educators enhance the learning experience for students in the classroom. These teacher tools make it easier for teachers to share their knowledge with the students while making the learning process exciting, engaging, and memorable.\\\\n3. What are the most commonly used teaching aids? [...] Bloomz is an interactive app that helps teachers and schools share updates, events, and photos with parents securely. You can also send alerts about upcoming parent-teacher meetings to emails and smartphones with a single click.\\\\nAssessment Tools in Teaching\\\\nThese educational tools are used to assess students\\u2019 knowledge, assign homework, and record grades.\\\\n47. Plickers [...] Printed materials like textbooks, workbooks, handouts, and worksheets.\\\\nProjectors and screens to display slideshows, videos, animations, and multimedia content.\\\\nVisual aids like posters, charts, graphs, and diagrams.\\\\nAudio-visual materials such as educational videos, documentaries, podcasts, and audio recordings.\\\\nModels, puzzles, blocks, and other hands-on materials, especially in subjects like mathematics and science.\\\"}, {\\\"url\\\": \\\"https://managedmethods.com/blog/top-20-tools-for-teaching-and-learning/\\\", \\\"content\\\": \\\"October 31, 2024 \\u2022 Classroom Management\\\\nTop 20 Tools for Teaching and Learning\\\\nTeachers and students have never had as much access to educational resources as they do today. With technology at the driving seat of today\\u2019s education sector, teachers are tasked with determining which solutions will maximize learning outcomes.\\\\nFrom video conferencing tools and learning management systems to more novel solutions like virtual reality and artificial intelligence (AI), the choices are endless. [...] On the parent front, these tools provide a platform for regular updates on student progress, direct messaging capabilities with educators, and access to upcoming school events and homework assignments\\u00a0\\u2014 keeping parents engaged and informed about their child\\u2019s educational journey.\\\\n7. Digital feedback tools [...] From the graphic design capabilities of Canva to the video creation solutions of Adobe Premiere Pro, these platforms empower educators to create professional-quality educational content that can engage and inspire students. Such tools are invaluable for crafting visual aids, instructional videos, and interactive media that enhance the learning experience.\\\"}, {\\\"url\\\": \\\"https://toptools4learning.com/\\\", \\\"content\\\": \\\"up 7 | 80 | Nearpod | educational tool for interactive presentations\\\\nBACK | 81 | Feedly | RSS/news reader\\\\nBACK | 82 | Khan Academy | online course library\\\\ndown 28 | 83 | Whereby | video meeting platform\\\\nBACK | 84 | Firefox | web browser\\\\ndown 45 | 85 | Quizizz | educational games and testing tool\\\\ndown 17 | 86 | Prezi | online presentation tool\\\\nBACK | 87 | Raindrop | bookmark manager\\\\nBACK | 88 | Descript | audio and video editing tool [...] up 23 | 28 | Masterclass | streaming platform for video lessons\\\\ndown 6 | 29 | Outlook | email client\\\\nup 2 | 30 | TED Talks | inspirational videos\\\\nup 3 | 31 | Duolingo | language learning app\\\\nup 12 | 32 | Quizlet | educational games and testing tool\\\\nup 6 | 33 | Moodle | open source learning platform\\\\ndown 15 | 34 | Vimeo | video hosting and sharing platform\\\\ndown 20 | 35 | Google Classroom | educational learning platform\\\\nup 6 | 36 | hihaho | interactive video tool\\\"}, {\\\"url\\\": \\\"https://www.education.com/\\\", \\\"content\\\": \\\"Sign up to start collecting!\\\\nBookmark this to easily find it later. Then send your curated collection to your children, or put together your own custom lesson plan.\\\\nSign up Log in\\\\nEducational Tools\\\\n\\\\nLearning Library\\\\nWorksheets\\\\nGames\\\\nInteractive Worksheets\\\\nWorksheet Generator\\\\nLesson Plans\\\\nCommon Core Resources\\\\n\\\\nSupport\\\\n\\\\nHelp center\\\\nPricing\\\\nEducation.com For Schools\\\\nGet a Quote\\\\nGive Gift\\\\nRedeem Gift\\\\nContact Us\\\"}]\",\n","      \"additional_kwargs\": {},\n","      \"response_metadata\": {},\n","      \"type\": \"tool\",\n","      \"name\": \"tavily_search_results_json\",\n","      \"id\": \"8fed5f8f-ac20-4146-9ab4-187370c125f7\",\n","      \"tool_call_id\": \"chatcmpl-tool-d4b03986ce184a2cb603c27ad80a79af\",\n","      \"artifact\": {\n","        \"query\": \"educational tools\",\n","        \"follow_up_questions\": null,\n","        \"answer\": null,\n","        \"images\": [\n","          \"https://www.hurix.com/wp-content/uploads/2023/06/Top-Digital-learning-tools-768x768.jpg\",\n","          \"https://www.acadecraft.com/blog/uploads/blog/2023/04/digital-education-tools-for-teachers-and-studentswebp.webp\",\n","          \"https://www.eschoolnews.com/files/2020/09/digital-learning-tools.jpg\",\n","          \"https://pocketofpreschool.com/wp-content/uploads/2017/11/Favorite-Teacher-Tools-Cover-Edited.jpg\",\n","          \"https://esomake.co.ke/images/blog-images/digital-learning-tools.jpg\"\n","        ],\n","        \"results\": [\n","          {\n","            \"url\": \"https://educational.tools/\",\n","            \"title\": \"Educational Tools - Education portal for digital productivity online\",\n","            \"content\": \"Educational Tools (\\u00a9 EduTools) is an educational portal that centralizes digital resources and applications to support teaching and learning.\",\n","            \"score\": 0.9368016,\n","            \"raw_content\": null\n","          },\n","          {\n","            \"url\": \"https://www.ispringsolutions.com/blog/free-teaching-tools\",\n","            \"title\": \"The 52 Best Free Online Teaching Tools in 2025 - iSpring\",\n","            \"content\": \"2. Why are teaching tools needed in education?\\nTeaching tools are designed to help educators enhance the learning experience for students in the classroom. These teacher tools make it easier for teachers to share their knowledge with the students while making the learning process exciting, engaging, and memorable.\\n3. What are the most commonly used teaching aids? [...] Bloomz is an interactive app that helps teachers and schools share updates, events, and photos with parents securely. You can also send alerts about upcoming parent-teacher meetings to emails and smartphones with a single click.\\nAssessment Tools in Teaching\\nThese educational tools are used to assess students\\u2019 knowledge, assign homework, and record grades.\\n47. Plickers [...] Printed materials like textbooks, workbooks, handouts, and worksheets.\\nProjectors and screens to display slideshows, videos, animations, and multimedia content.\\nVisual aids like posters, charts, graphs, and diagrams.\\nAudio-visual materials such as educational videos, documentaries, podcasts, and audio recordings.\\nModels, puzzles, blocks, and other hands-on materials, especially in subjects like mathematics and science.\",\n","            \"score\": 0.78963995,\n","            \"raw_content\": null\n","          },\n","          {\n","            \"url\": \"https://managedmethods.com/blog/top-20-tools-for-teaching-and-learning/\",\n","            \"title\": \"Top 20 tools for Teaching and Learning | ManagedMethods\",\n","            \"content\": \"October 31, 2024 \\u2022 Classroom Management\\nTop 20 Tools for Teaching and Learning\\nTeachers and students have never had as much access to educational resources as they do today. With technology at the driving seat of today\\u2019s education sector, teachers are tasked with determining which solutions will maximize learning outcomes.\\nFrom video conferencing tools and learning management systems to more novel solutions like virtual reality and artificial intelligence (AI), the choices are endless. [...] On the parent front, these tools provide a platform for regular updates on student progress, direct messaging capabilities with educators, and access to upcoming school events and homework assignments\\u00a0\\u2014 keeping parents engaged and informed about their child\\u2019s educational journey.\\n7. Digital feedback tools [...] From the graphic design capabilities of Canva to the video creation solutions of Adobe Premiere Pro, these platforms empower educators to create professional-quality educational content that can engage and inspire students. Such tools are invaluable for crafting visual aids, instructional videos, and interactive media that enhance the learning experience.\",\n","            \"score\": 0.6778372,\n","            \"raw_content\": null\n","          },\n","          {\n","            \"url\": \"https://toptools4learning.com/\",\n","            \"title\": \"Top 100 Tools for Learning 2024 \\u2013 Results of the 18th Annual ...\",\n","            \"content\": \"up 7 | 80 | Nearpod | educational tool for interactive presentations\\nBACK | 81 | Feedly | RSS/news reader\\nBACK | 82 | Khan Academy | online course library\\ndown 28 | 83 | Whereby | video meeting platform\\nBACK | 84 | Firefox | web browser\\ndown 45 | 85 | Quizizz | educational games and testing tool\\ndown 17 | 86 | Prezi | online presentation tool\\nBACK | 87 | Raindrop | bookmark manager\\nBACK | 88 | Descript | audio and video editing tool [...] up 23 | 28 | Masterclass | streaming platform for video lessons\\ndown 6 | 29 | Outlook | email client\\nup 2 | 30 | TED Talks | inspirational videos\\nup 3 | 31 | Duolingo | language learning app\\nup 12 | 32 | Quizlet | educational games and testing tool\\nup 6 | 33 | Moodle | open source learning platform\\ndown 15 | 34 | Vimeo | video hosting and sharing platform\\ndown 20 | 35 | Google Classroom | educational learning platform\\nup 6 | 36 | hihaho | interactive video tool\",\n","            \"score\": 0.64826655,\n","            \"raw_content\": null\n","          },\n","          {\n","            \"url\": \"https://www.education.com/\",\n","            \"title\": \"Education.com | #1 Educational Site for Pre-K to 8th Grade\",\n","            \"content\": \"Sign up to start collecting!\\nBookmark this to easily find it later. Then send your curated collection to your children, or put together your own custom lesson plan.\\nSign up Log in\\nEducational Tools\\n\\nLearning Library\\nWorksheets\\nGames\\nInteractive Worksheets\\nWorksheet Generator\\nLesson Plans\\nCommon Core Resources\\n\\nSupport\\n\\nHelp center\\nPricing\\nEducation.com For Schools\\nGet a Quote\\nGive Gift\\nRedeem Gift\\nContact Us\",\n","            \"score\": 0.64182705,\n","            \"raw_content\": null\n","          }\n","        ],\n","        \"response_time\": 3.56\n","      },\n","      \"status\": \"success\"\n","    },\n","    {\n","      \"content\": \"Based on the search results, here are some tools for education:\\n\\n1. Educational Tools (EduTools) - a portal that centralizes digital resources and applications to support teaching and learning.\\n2. Bloomz - an interactive app that helps teachers and schools share updates, events, and photos with parents securely.\\n3. Plickers - a tool used to assess students' knowledge, assign homework, and record grades.\\n4. Printed materials like textbooks, workbooks, handouts, and worksheets.\\n5. Projectors and screens to display slideshows, videos, animations, and multimedia content.\\n6. Visual aids like posters, charts, graphs, and diagrams.\\n7. Audio-visual materials such as educational videos, documentaries, podcasts, and audio recordings.\\n8. Models, puzzles, blocks, and other hands-on materials, especially in subjects like mathematics and science.\\n9. Video conferencing tools and learning management systems.\\n10. Digital feedback tools.\\n11. Canva - a graphic design platform that empowers educators to create professional-quality educational content.\\n12. Adobe Premiere Pro - a video creation platform that empowers educators to create professional-quality educational content.\\n13. Nearpod - an educational tool for interactive presentations.\\n14. Feedly - an RSS/news reader.\\n15. Khan Academy - an online course library.\\n16. Whereby - a video meeting platform.\\n17. Firefox - a web browser.\\n18. Quizizz - an educational games and testing tool.\\n19. Prezi - an online presentation tool.\\n20. Raindrop - a bookmark manager.\\n21. Descript - an audio and video editing tool.\\n22. Masterclass - a streaming platform for video lessons.\\n23. Outlook - an email client.\\n24. TED Talks - inspirational videos.\\n25. Duolingo - a language learning app.\\n26. Quizlet - an educational games and testing tool.\\n27. Moodle - an open-source learning platform.\\n28. Vimeo - a video hosting and sharing platform.\\n29. Google Classroom - an educational learning platform.\\n30. hihaho - an interactive video tool.\\n\\nThese tools can be used to enhance the learning experience for students, engage parents, and support teachers in their instructional endeavors.\",\n","      \"additional_kwargs\": {},\n","      \"response_metadata\": {\n","        \"role\": \"assistant\",\n","        \"content\": \"Based on the search results, here are some tools for education:\\n\\n1. Educational Tools (EduTools) - a portal that centralizes digital resources and applications to support teaching and learning.\\n2. Bloomz - an interactive app that helps teachers and schools share updates, events, and photos with parents securely.\\n3. Plickers - a tool used to assess students' knowledge, assign homework, and record grades.\\n4. Printed materials like textbooks, workbooks, handouts, and worksheets.\\n5. Projectors and screens to display slideshows, videos, animations, and multimedia content.\\n6. Visual aids like posters, charts, graphs, and diagrams.\\n7. Audio-visual materials such as educational videos, documentaries, podcasts, and audio recordings.\\n8. Models, puzzles, blocks, and other hands-on materials, especially in subjects like mathematics and science.\\n9. Video conferencing tools and learning management systems.\\n10. Digital feedback tools.\\n11. Canva - a graphic design platform that empowers educators to create professional-quality educational content.\\n12. Adobe Premiere Pro - a video creation platform that empowers educators to create professional-quality educational content.\\n13. Nearpod - an educational tool for interactive presentations.\\n14. Feedly - an RSS/news reader.\\n15. Khan Academy - an online course library.\\n16. Whereby - a video meeting platform.\\n17. Firefox - a web browser.\\n18. Quizizz - an educational games and testing tool.\\n19. Prezi - an online presentation tool.\\n20. Raindrop - a bookmark manager.\\n21. Descript - an audio and video editing tool.\\n22. Masterclass - a streaming platform for video lessons.\\n23. Outlook - an email client.\\n24. TED Talks - inspirational videos.\\n25. Duolingo - a language learning app.\\n26. Quizlet - an educational games and testing tool.\\n27. Moodle - an open-source learning platform.\\n28. Vimeo - a video hosting and sharing platform.\\n29. Google Classroom - an educational learning platform.\\n30. hihaho - an interactive video tool.\\n\\nThese tools can be used to enhance the learning experience for students, engage parents, and support teachers in their instructional endeavors.\",\n","        \"token_usage\": {\n","          \"prompt_tokens\": 1272,\n","          \"total_tokens\": 1715,\n","          \"completion_tokens\": 443\n","        },\n","        \"finish_reason\": \"stop\",\n","        \"model_name\": \"nvdev/meta/llama-3.1-70b-instruct\"\n","      },\n","      \"type\": \"ai\",\n","      \"name\": null,\n","      \"id\": \"run-fd9586f5-c66e-499a-8e36-c70909f9a3b9-0\",\n","      \"example\": false,\n","      \"tool_calls\": [],\n","      \"invalid_tool_calls\": [],\n","      \"usage_metadata\": {\n","        \"input_tokens\": 1272,\n","        \"output_tokens\": 443,\n","        \"total_tokens\": 1715\n","      },\n","      \"role\": \"assistant\"\n","    }\n","  ]\n","}\n"]}],"source":["search = TavilySearchResults(max_results=5, include_images=True)\n","tools = [search]\n","agent = create_react_agent(llm, tools)\n","\n","response = agent.invoke(\n","    {\"messages\": [{\"role\": \"user\", \"content\": \"What are some tools for education?\"}]})\n","\n","print(\"\\n================================== Ai Message ==================================\")\n","print(response[\"messages\"][-1].content)\n","\n","print(json.dumps(response, indent=2, default=custom_serializer))"]},{"cell_type":"markdown","metadata":{"id":"K3hJ93eS5Ux5"},"source":["\n","<summary><strong>What do we observe?</strong></summary>\n","\n","The above shows the following results from the Tavily tool calling, which will give you the top 5 web results (specified 5 in `max_results`).\n","\n","-  `images`: Images from the website links which can be used as thumbnail if required.\n","- `results`: Specific information for each of the 5 web results, such as `url`, `title`, `content` (brief description), `score` (relevancy scoring).\n","- `content`: LLM answer to the query based on the web search results."]},{"cell_type":"markdown","metadata":{"id":"km_DIEeJ1DTJ"},"source":["# üß† Third Capability: ReAct Agent with Memory + Tavily\n","\n","Now, we are implementing the ReAct agent with both the Tavily web search tool and conversational memory.\n","\n","This was the previously created `State` (structured Dict)."]},{"cell_type":"code","execution_count":19,"metadata":{"id":"C4Eq7xj_1DTJ"},"outputs":[],"source":["class State(TypedDict):\n","    # The \"messages\" key is a list.\n","    # The `add_messages` annotation tells our system to **append** new messages\n","    # to this list instead of replacing the entire list.\n","    messages: Annotated[list, add_messages]"]},{"cell_type":"markdown","metadata":{"id":"jID7h5R11DTJ"},"source":["In order to use create_react_agent, we will need to use an additional `is_last_step` parameter. The is_last_step flag and remaining_steps integer coordinate the decision-making process in a ReAct pipeline‚Äîparticularly for managing when the Tavily tool calls should cease."]},{"cell_type":"code","execution_count":18,"metadata":{"id":"TBfejNRQ1DTJ"},"outputs":[],"source":["class TavilyState(TypedDict):\n","        messages: Annotated[list, add_messages]\n","        is_last_step: str\n","        remaining_steps: int"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"_dRohaiN1DTJ"},"outputs":[],"source":["# Creating a new function to print the stream, taking into account the tool calling different printing (unable to do automatic pretty_print)\n","def print_stream(graph, inputs, config):\n","    for s in graph.stream(inputs, config, stream_mode=\"values\"):\n","        message = s[\"messages\"][-1]\n","        if isinstance(message, tuple): # To enable tool calling printing\n","            print(message)\n","        else:\n","            message.pretty_print()"]},{"cell_type":"markdown","metadata":{"id":"EYeeU4so1DTJ"},"source":["Lastly, we are creating the react agent which implements the LangGraph graphing logic previously explored within the function.\n","\n","We do not have to explicitly create our own StateGraph now, it is implemented within the pre-built `create_react_agent` function.\n","\n","This enables us to pass in the memory in the same way as before using `MemorySaver()`.\n","\n","The Tavily tool is also implemented for web search capabilities, creating a ReAct agent with conversational memory + web search capabilities.\n","\n","![flowchart-tavily.png](img/flowchart-tavily.png)"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1742261611201,"user":{"displayName":"Darren Tan SG","userId":"07785499131391784730"},"user_tz":-480},"id":"oHmCLixb1DTJ","outputId":"0a49ba0d-c6d9-4c26-d6b2-c3e3bc5894d2"},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/jewel/.pyenv/versions/3.11.7/lib/python3.11/site-packages/langchain_nvidia_ai_endpoints/chat_models.py:591: UserWarning: Model 'nvdev/meta/llama-3.1-70b-instruct' is not known to support tools. Your tool binding may fail at inference time.\n","  warnings.warn(\n"]}],"source":["search = TavilySearchResults(max_results=5, include_images=True)\n","tools = [search]\n","memory_tavily = MemorySaver()\n","\n","graph_with_tavily = create_react_agent(llm, tools, state_schema=TavilyState, checkpointer=memory_tavily)"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"QeO6pL2Y5Ux6"},"outputs":[],"source":["thread_id = \"memory_and_tavily_2\""]},{"cell_type":"code","execution_count":22,"metadata":{"id":"6TNP1UgK5Ux6","outputId":"6bc39369-2363-4108-f000-188ec0680c71"},"outputs":[{"name":"stdout","output_type":"stream","text":["================================\u001b[1m Human Message \u001b[0m=================================\n","\n","Hi, I'm Will! Nice to meet you. I'm a teacher.\n","==================================\u001b[1m Ai Message \u001b[0m==================================\n","\n","Nice to meet you too, Will! It's great to hear that you're a teacher. What subject do you teach, if I might ask?\n"]}],"source":["config = {\"configurable\": {\"thread_id\": thread_id}}\n","\n","inputs = {\"messages\": [(\"user\", \"Hi, I'm Will! Nice to meet you. I'm a teacher.\")]}\n","print_stream(graph_with_tavily, inputs, config)"]},{"cell_type":"markdown","metadata":{"id":"ChChYAhg1DTJ"},"source":["The LLM determines whether tool calling is required. It has correctly decided not to call Tavily as web search capabilities are not required.\n","\n","Let's look at what's happening behind the scenes."]},{"cell_type":"code","execution_count":23,"metadata":{"id":"Mr_1D-rD5Ux6","outputId":"97d1257c-cf9c-44b2-e9c8-2592137d2775"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","====================== What is happening behind the scenes:======================\n","{\n","  \"v\": 2,\n","  \"ts\": \"2025-05-08T07:06:29.407678+00:00\",\n","  \"id\": \"1f02bdaf-6ecf-6dd0-8001-c9e7e3a4abbe\",\n","  \"channel_versions\": {\n","    \"__start__\": \"00000000000000000000000000000002.0.6920170914791764\",\n","    \"messages\": \"00000000000000000000000000000003.0.2788241362496966\",\n","    \"branch:to:agent\": \"00000000000000000000000000000003.0.8998049767662768\"\n","  },\n","  \"versions_seen\": {\n","    \"__input__\": {},\n","    \"__start__\": {\n","      \"__start__\": \"00000000000000000000000000000001.0.11357132653854018\"\n","    },\n","    \"agent\": {\n","      \"branch:to:agent\": \"00000000000000000000000000000002.0.6002830501976488\"\n","    }\n","  },\n","  \"channel_values\": {\n","    \"messages\": [\n","      {\n","        \"content\": \"Hi, I'm Will! Nice to meet you. I'm a teacher.\",\n","        \"additional_kwargs\": {},\n","        \"response_metadata\": {},\n","        \"type\": \"human\",\n","        \"name\": null,\n","        \"id\": \"dd149ef1-4398-4da2-be15-f99f5420e276\",\n","        \"example\": false\n","      },\n","      {\n","        \"content\": \"Nice to meet you too, Will! It's great to hear that you're a teacher. What subject do you teach, if I might ask?\",\n","        \"additional_kwargs\": {},\n","        \"response_metadata\": {\n","          \"role\": \"assistant\",\n","          \"content\": \"Nice to meet you too, Will! It's great to hear that you're a teacher. What subject do you teach, if I might ask?\",\n","          \"token_usage\": {\n","            \"prompt_tokens\": 323,\n","            \"total_tokens\": 353,\n","            \"completion_tokens\": 30\n","          },\n","          \"finish_reason\": \"stop\",\n","          \"model_name\": \"nvdev/meta/llama-3.1-70b-instruct\"\n","        },\n","        \"type\": \"ai\",\n","        \"name\": null,\n","        \"id\": \"run-c16d6e92-9b61-453a-9a68-75fb30fbdaab-0\",\n","        \"example\": false,\n","        \"tool_calls\": [],\n","        \"invalid_tool_calls\": [],\n","        \"usage_metadata\": {\n","          \"input_tokens\": 323,\n","          \"output_tokens\": 30,\n","          \"total_tokens\": 353\n","        },\n","        \"role\": \"assistant\"\n","      }\n","    ]\n","  },\n","  \"pending_sends\": []\n","}\n"]}],"source":["print(\"\\n====================== What is happening behind the scenes:======================\")\n","print(json.dumps(memory_tavily.get(config), indent=2, default=custom_serializer))"]},{"cell_type":"markdown","metadata":{"id":"1mQRp9mS5Ux6"},"source":["<summary><strong>What do we observe?</strong></summary>\n","\n","In the second element of `messages` (the AI message), you can observe `\"tool_calls\": []`. This correctly shows no tools were called in this run."]},{"cell_type":"markdown","metadata":{"id":"QsUx6o4l1DTJ"},"source":["Let's now test the conversational memory property. Will the LLM be able to remember the user's job without the user mentioning it a second time? And, will it also be able to search for relevant web articles using Tavily?"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"EA-uADDo5Ux6","outputId":"b88d6c7c-2dbd-4202-8a26-3c9581723354"},"outputs":[{"name":"stdout","output_type":"stream","text":["================================\u001b[1m Human Message \u001b[0m=================================\n","\n","Can you give me some articles on how AI can help me with my job?\n","==================================\u001b[1m Ai Message \u001b[0m==================================\n","\n","<|python_tag|>tavily_search_results_json{\"query\": \"AI for educators\"}\n"]}],"source":["inputs = {\"messages\": [(\"user\", \"Can you give me some articles on how AI can help me with my job?\")]}\n","print_stream(graph_with_tavily, inputs, config)"]},{"cell_type":"markdown","metadata":{"id":"aNQ7JefY5Ux6"},"source":["Great! From Tool Message, you can see that the Tavily tool is called and it returns some web results.\n","\n","Let's take a closer look."]},{"cell_type":"code","execution_count":25,"metadata":{"id":"H6x4rZc25Ux7","outputId":"3d0201af-e71c-4a4b-ab6f-35a987503da7"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","====================== What is happening behind the scenes:======================\n","{\n","  \"v\": 2,\n","  \"ts\": \"2025-05-08T07:07:49.671462+00:00\",\n","  \"id\": \"1f02bdb2-6c44-65fe-8004-ca1a06ed29c1\",\n","  \"channel_versions\": {\n","    \"__start__\": \"00000000000000000000000000000005.0.276390468609507\",\n","    \"messages\": \"00000000000000000000000000000006.0.4662012362191299\",\n","    \"branch:to:agent\": \"00000000000000000000000000000006.0.5937524713461495\"\n","  },\n","  \"versions_seen\": {\n","    \"__input__\": {},\n","    \"__start__\": {\n","      \"__start__\": \"00000000000000000000000000000004.0.6277740333844445\"\n","    },\n","    \"agent\": {\n","      \"branch:to:agent\": \"00000000000000000000000000000005.0.08908218451655314\"\n","    }\n","  },\n","  \"channel_values\": {\n","    \"messages\": [\n","      {\n","        \"content\": \"Hi, I'm Will! Nice to meet you. I'm a teacher.\",\n","        \"additional_kwargs\": {},\n","        \"response_metadata\": {},\n","        \"type\": \"human\",\n","        \"name\": null,\n","        \"id\": \"dd149ef1-4398-4da2-be15-f99f5420e276\",\n","        \"example\": false\n","      },\n","      {\n","        \"content\": \"Nice to meet you too, Will! It's great to hear that you're a teacher. What subject do you teach, if I might ask?\",\n","        \"additional_kwargs\": {},\n","        \"response_metadata\": {\n","          \"role\": \"assistant\",\n","          \"content\": \"Nice to meet you too, Will! It's great to hear that you're a teacher. What subject do you teach, if I might ask?\",\n","          \"token_usage\": {\n","            \"prompt_tokens\": 323,\n","            \"total_tokens\": 353,\n","            \"completion_tokens\": 30\n","          },\n","          \"finish_reason\": \"stop\",\n","          \"model_name\": \"nvdev/meta/llama-3.1-70b-instruct\"\n","        },\n","        \"type\": \"ai\",\n","        \"name\": null,\n","        \"id\": \"run-c16d6e92-9b61-453a-9a68-75fb30fbdaab-0\",\n","        \"example\": false,\n","        \"tool_calls\": [],\n","        \"invalid_tool_calls\": [],\n","        \"usage_metadata\": {\n","          \"input_tokens\": 323,\n","          \"output_tokens\": 30,\n","          \"total_tokens\": 353\n","        },\n","        \"role\": \"assistant\"\n","      },\n","      {\n","        \"content\": \"Can you give me some articles on how AI can help me with my job?\",\n","        \"additional_kwargs\": {},\n","        \"response_metadata\": {},\n","        \"type\": \"human\",\n","        \"name\": null,\n","        \"id\": \"65336bec-43e9-4670-a4e4-652e93168924\",\n","        \"example\": false\n","      },\n","      {\n","        \"content\": \"<|python_tag|>tavily_search_results_json{\\\"query\\\": \\\"AI for teachers\\\"}\",\n","        \"additional_kwargs\": {},\n","        \"response_metadata\": {\n","          \"role\": \"assistant\",\n","          \"content\": \"<|python_tag|>tavily_search_results_json{\\\"query\\\": \\\"AI for teachers\\\"}\",\n","          \"token_usage\": {\n","            \"prompt_tokens\": 379,\n","            \"total_tokens\": 395,\n","            \"completion_tokens\": 16\n","          },\n","          \"finish_reason\": \"stop\",\n","          \"model_name\": \"nvdev/meta/llama-3.1-70b-instruct\"\n","        },\n","        \"type\": \"ai\",\n","        \"name\": null,\n","        \"id\": \"run-bc75804f-0561-46f9-bfb5-bfd0e182a131-0\",\n","        \"example\": false,\n","        \"tool_calls\": [],\n","        \"invalid_tool_calls\": [],\n","        \"usage_metadata\": {\n","          \"input_tokens\": 379,\n","          \"output_tokens\": 16,\n","          \"total_tokens\": 395\n","        },\n","        \"role\": \"assistant\"\n","      }\n","    ]\n","  },\n","  \"pending_sends\": []\n","}\n"]}],"source":["print(\"\\n====================== What is happening behind the scenes:======================\")\n","print(json.dumps(memory_tavily.get(config), indent=2, default=custom_serializer))"]},{"cell_type":"markdown","metadata":{"id":"TrAvDisS1DTK"},"source":["<summary><strong>What do we observe?</strong></summary>\n","\n","Now, in the same `\"tool_calls\"` parameter we were observing before, you can see that it is not empty. `tavily_search_results_json` specifies the name of the tool that has been called correctly when asked for web articles. The query `AI for teachers` show that there was conversational memory that the user's job was a teacher from the first Human message sent before."]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"venv_jup","language":"python","name":"venv_jup"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":0}
